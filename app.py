# ==========================================================
# OPS2TBM â€” ì•ˆì „ êµìœ¡ ë° ì ê²€ ì¼ì§€ ë°˜ì˜ (TBM ë° ì¼ì¼ì•ˆì „êµìœ¡ ì¼ì§€ í™•ì¥)
#  - ê¸°ì¡´ UI/ë ˆì´ì•„ì›ƒ ìœ ì§€, ë¬¸ì„œì— ì¶”ê°€ í•„ë“œ í¬í•¨
# ==========================================================

import io, zipfile, re
from collections import Counter
from typing import List, Dict
import streamlit as st
from docx import Document
from docx.shared import Pt
from pdfminer.high_level import extract_text as pdf_extract_text  # ì•ˆì • ê²½ë¡œ
import pypdfium2 as pdfium
import numpy as np
import regex as rxx

# ----------------------------
# ì„¸ì…˜ ìƒíƒœ
# ----------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì—…ë¡œë“œí•œ íŒŒì¼ì˜ í‚¤ê°’, ìš©ì–´/í–‰ë™/ì§ˆë¬¸ ìš©ì–´ ì§‘í•©ì„ ì €ì¥)
if "uploader_key" not in st.session_state:
    st.session_state.uploader_key = 0
if "kb_terms" not in st.session_state:
    st.session_state.kb_terms: Counter = Counter()
if "kb_actions" not in st.session_state:
    st.session_state.kb_actions: List[str] = []
if "kb_questions" not in st.session_state:
    st.session_state.kb_questions: List[str] = []

# ==========================================================
# ì „ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ì •ë¦¬
# ==========================================================
# ì¡ìŒ íŒ¨í„´(ë¶ˆí•„ìš”í•œ í—¤ë”, ë§í¬ ë“±ì„ ì œê±°í•˜ê¸° ìœ„í•œ ì •ê·œì‹)
NOISE_PATTERNS = [
    r"^ì œ?\s?\d{4}\s?[-.]?\s?\d+\s?í˜¸$",
    r"^(ë™ì ˆê¸°\s*ì£¼ìš”ì‚¬ê³ |ì•ˆì „ì‘ì—…ë°©ë²•|ì½˜í…ì¸ ë§í¬|ì±…ì\s*OPS|ìˆí¼\s*OPS)$",
    r"^(í¬ìŠ¤í„°|ì±…ì|ìŠ¤í‹°ì»¤|ì½˜í…ì¸  ë§í¬)$",
    r"^(ìŠ¤ë§ˆíŠ¸í°\s*APP|ì¤‘ëŒ€ì¬í•´\s*ì‚¬ì´ë Œ|ì‚°ì—…ì•ˆì „í¬í„¸|ê³ ìš©ë…¸ë™ë¶€)$",
    r"^https?://\S+$",
    r"^\(?\s*PowerPoint\s*í”„ë ˆì  í…Œì´ì…˜\s*\)?$",
    r"^ì•ˆì „ë³´ê±´ìë£Œì‹¤.*$",
]
# ë¶ˆë¦¿í¬ì¸íŠ¸ ë¬¸ì íŒ¨í„´
BULLET_PREFIX = r"^[\s\-\â€¢\â—\â–ª\â–¶\â–·\Â·\*\u25CF\u25A0\u25B6\u25C6\u2022\u00B7\u279C\u27A4\u25BA\u25AA\u25AB\u2611\u2713\u2714\u2716\u2794\u27A2]+"
# ë‚ ì§œ íŒ¨í„´
DATE_PAT = r"(\d{4})\.\s?(\d{1,2})\.\s?(\d{1,2})\.?"
# ì‚¬ê³ ì‚¬ë¡€ì—ì„œ ë‚˜íƒ€ë‚  ìˆ˜ ìˆëŠ” íŒ¨í„´
META_PATTERNS = [r"<\s*\d+\s*ëª…\s*ì‚¬ë§\s*>", r"<\s*\d+\s*ëª…\s*ì‚¬ìƒ\s*>", r"<\s*\d+\s*ëª…\s*ì˜ì‹ë¶ˆëª…\s*>"]
# ë¶ˆìš©ì–´(êµ¬ë¶„ëœ ìš©ì–´ë¡œë¶€í„° ì œê±°í•  ë‹¨ì–´ë“¤)
STOP_TERMS = set([
    "ë°","ë“±","ê´€ë ¨","ì‚¬í•­","ë‚´ìš©","ì˜ˆë°©","ì•ˆì „","ì‘ì—…","í˜„ì¥","êµìœ¡","ë°©ë²•","ê¸°ì¤€","ì¡°ì¹˜",
    "ì‹¤ì‹œ","í™•ì¸","í•„ìš”","ê²½ìš°","ëŒ€ìƒ","ì‚¬ìš©","ê´€ë¦¬","ì ê²€","ì ìš©","ì •ë„","ì£¼ì˜","ì¤‘","ì „","í›„",
    "ì£¼ìš”","ì‚¬ë¡€","ì•ˆì „ì‘ì—…ë°©ë²•","í¬ìŠ¤í„°","ë™ì˜ìƒ","ë¦¬í”Œë¦¿","ê°€ì´ë“œ","ìë£Œì‹¤","ê²€ìƒ‰",
])

def normalize_text(t: str) -> str:
    t = t.replace("\x0c","\n")
    t = re.sub(r"[ \t]+\n","\n",t)
    t = re.sub(r"\n{3,}","\n\n",t)
    return t.strip()

def strip_noise_line(line: str) -> str:
    """ë¼ì¸ì—ì„œ ë¶ˆí•„ìš”í•œ ë¬¸ìë¥¼ ì œê±°í•˜ê³  í•„ìš”í•œ ë¬¸ì¥ë§Œ ë°˜í™˜"""
    s = (line or "").strip()
    if not s: return ""
    s = re.sub(BULLET_PREFIX,"",s).strip()
    for pat in NOISE_PATTERNS:
        if re.match(pat,s,re.IGNORECASE):
            return ""
    s = re.sub(r"https?://\S+","",s).strip()
    s = s.strip("â€¢â—â–ªâ–¶â–·Â·-â€”â€“")
    return s

def merge_broken_lines(lines: List[str]) -> List[str]:
    """ì¤„ ë ë¬¸ì¥ë¶€í˜¸/ë¨¸ë¦¬í‘œì‹œì— ë”°ë¼ ìì—° ë³‘í•©"""
    out=[]; buf=""
    for raw in lines:
        s = strip_noise_line(raw)
        if not s: continue
        s = s.lstrip("â†³").strip()
        if buf and (buf.endswith((":", "Â·", "â€¢", "â–ª", "â–¶", "â–·")) or re.match(r"^\(.*\)$", buf)):
            buf += " " + s
        else:
            if buf: out.append(buf)
            buf = s
    if buf: out.append(buf)
    return out

def combine_date_with_next(lines: List[str]) -> List[str]:
    """YYYY.MM.DD ë‹¤ìŒ ì¤„ì˜ 'ì‚¬ê³ /ì‚¬ë§/ì¤‘ë…/ë¬´ë„ˆì§/ë¶€ë”ªí˜...'ê³¼ ê²°í•©í•´ ì‚¬ê±´ë¬¸ í˜•íƒœë¡œ"""
    out=[]; i=0
    while i<len(lines):
        cur=strip_noise_line(lines[i])
        if re.search(DATE_PAT,cur) and (i+1)<len(lines):
            nxt=strip_noise_line(lines[i+1])
            if re.search(r"(ì‚¬ë§|ì‚¬ìƒ|ì‚¬ê³ |ì¤‘ë…|í™”ì¬|ë¶•ê´´|ì§ˆì‹|ì¶”ë½|ê¹”ë¦¼|ë¶€ë”ªí˜|ë¬´ë„ˆì§)",nxt):
                m=re.search(DATE_PAT,cur); y,mo,d=m.groups()
                out.append(f"{int(y)}ë…„ {int(mo)}ì›” {int(d)}ì¼, {nxt}")
                i+=2; continue
        out.append(cur); i+=1
    return out

def preprocess_text_to_sentences(text: str) -> List[str]:
    """ë¬¸ì„œì—ì„œ í´ë¦° ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    text = normalize_text(text)
    raw_lines = [ln for ln in text.splitlines() if ln.strip()]
    lines = merge_broken_lines(raw_lines)
    lines = combine_date_with_next(lines)
    joined = "\n".join(lines)
    raw = rxx.split(r"(?<=[\.!\?]|ë‹¤\.)\s+|\n+", joined)
    sents=[]
    for s in raw:
        s2 = strip_noise_line(s)
        if not s2: continue
        if re.search(r"(ì£¼ìš”ì‚¬ê³ |ì•ˆì „ì‘ì—…ë°©ë²•|ì½˜í…ì¸ ë§í¬)$",s2): continue
        if len(s2)<6: continue
        sents.append(s2)
    # ì¤‘ë³µ ì œê±°
    seen=set(); dedup=[]
    for s in sents:
        k=re.sub(r"\s+","",s)
        if k not in seen:
            seen.add(k); dedup.append(s)
    return dedup

# ==========================================================
# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ í›„ ì²˜ë¦¬ - ë¹ˆ í…ìŠ¤íŠ¸ ì²´í¬ ì¶”ê°€
# ==========================================================
def read_pdf_text(b: bytes) -> str:
    """PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        with io.BytesIO(b) as bio:
            t = pdf_extract_text(bio) or ""
    except Exception:
        t = ""
    t = normalize_text(t)
    if len(t.strip()) < 10:  # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´, ì´ë¯¸ì§€/ìŠ¤ìº” PDFë¡œ íŒë‹¨
        try:
            with io.BytesIO(b) as bio:
                pdf = pdfium.PdfDocument(bio)
                if len(pdf) > 0 and not t.strip():
                    st.warning("âš ï¸ ì´ë¯¸ì§€/ìŠ¤ìº” PDFë¡œ ë³´ì…ë‹ˆë‹¤. í˜„ì¬ OCR ë¯¸ì§€ì›.")
        except Exception:
            pass
    return t

# ==========================================================
# ì—…ë¡œë“œ ì‹œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ (ë¹ˆ ê°’ ì²´í¬ ì¶”ê°€)
# ==========================================================
extracted = ""

# PDF íŒŒì¼ì„ ì—…ë¡œë“œí–ˆì„ ë•Œ, í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì²˜ë¦¬
if uploaded and uploaded.name.lower().endswith(".pdf"):
    with st.spinner("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
        data = uploaded.read()
        extracted = read_pdf_text(data)
        if extracted.strip():  # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆì§€ ì•Šì€ ê²½ìš°
            kb_ingest_text(extracted)   # ğŸ”¹ ë‹¨ì¼ PDFë„ ì¦‰ì‹œ í•™ìŠµ
            kb_prune()
        else:
            st.warning("âš ï¸ PDFì—ì„œ ìœ íš¨í•œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

elif selected_zip_pdf:
    with st.spinner("ZIP ë‚´ë¶€ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
        extracted = read_pdf_text(zip_pdfs[selected_zip_pdf])
        if extracted.strip():  # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆì§€ ì•Šì€ ê²½ìš°
            kb_ingest_text(extracted)  # ğŸ”¹ ë‹¨ì¼ PDFë„ ì¦‰ì‹œ í•™ìŠµ
            kb_prune()
        else:
            st.warning("âš ï¸ ZIPì—ì„œ PDFë¥¼ ì²˜ë¦¬í•˜ëŠ” ë™ì•ˆ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ìˆ˜ë™ í…ìŠ¤íŠ¸ ì…ë ¥ì´ ìˆì„ ê²½ìš°, ê·¸ ë˜í•œ í•™ìŠµ ë°˜ì˜
pasted = (st.session_state.get("manual_text") or "").strip()
if pasted:
    kb_ingest_text(pasted)
    kb_prune()

base_text = pasted or extracted.strip()

if not base_text:
    st.warning("âš ï¸ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. PDF ì—…ë¡œë“œ ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

# í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° í‘œì‹œ
st.markdown("**ì¶”ì¶œ/ì…ë ¥ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°**")
edited_text = st.text_area("í…ìŠ¤íŠ¸", value=base_text, height=240, key="edited_text")

# ==========================================================
# TBM ëŒ€ë³¸ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ
# ==========================================================
use_ai = st.toggle("ğŸ”¹ AI ìš”ì•½(TextRank+MMR) ì‚¬ìš©", value=True)
tmpl_choice = st.selectbox("ğŸ§© í…œí”Œë¦¿", ["ìë™ ì„ íƒ","ì‚¬ê³ ì‚¬ë¡€í˜•","ê°€ì´ë“œí˜•"])  # í‘œì‹œë§Œ ìœ ì§€
gen_mode = st.selectbox("ğŸ§  ìƒì„± ëª¨ë“œ", ["TBM ê¸°ë³¸(í˜„í–‰)","ìì—°ìŠ¤ëŸ¬ìš´ êµìœ¡ëŒ€ë³¸(ë¬´ë£Œ)"])
max_points = st.slider("ìš”ì•½ ê°•ë„(í•µì‹¬ë¬¸ì¥ ê°œìˆ˜)", 3, 10, 6)

if st.button("ğŸ› ï¸ ëŒ€ë³¸ ìƒì„±", type="primary", use_container_width=True):
    text_for_gen = (st.session_state.get("edited_text") or "").strip()
    if not text_for_gen:
        st.warning("í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. PDF/ZIP ì—…ë¡œë“œ ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ í›„ ì‹œë„í•˜ì„¸ìš”.")
    else:
        with st.spinner("ëŒ€ë³¸ ìƒì„± ì¤‘..."):
            if gen_mode == "ìì—°ìŠ¤ëŸ¬ìš´ êµìœ¡ëŒ€ë³¸(ë¬´ë£Œ)":
                script = make_structured_script(text_for_gen, max_points=max_points)
                subtitle = "ìì—°ìŠ¤ëŸ¬ìš´ êµìœ¡ëŒ€ë³¸(ë¬´ë£Œ)"
            else:
                sents = ai_extract_summary(text_for_gen, max_points if use_ai else 6)
                sents = [soften(s) for s in sents]
                script = "\n".join([f"- {s}" for s in sents]) if sents else "í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ë¬¸ì¥ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                subtitle = "TBM ê¸°ë³¸(í˜„í–‰)"

        st.success(f"ëŒ€ë³¸ ìƒì„± ì™„ë£Œ! ({subtitle})")
        st.text_area("ëŒ€ë³¸ ë¯¸ë¦¬ë³´ê¸°", value=script, height=420)
        c3,c4 = st.columns(2)
        with c3:
            st.download_button("â¬‡ï¸ TXT ë‹¤ìš´ë¡œë“œ", data=_xml_safe(script).encode("utf-8"),
                               file_name="tbm_script.txt", use_container_width=True)
        with c4:
            st.download_button("â¬‡ï¸ DOCX ë‹¤ìš´ë¡œë“œ", data=to_docx_bytes(script),
                               file_name="tbm_script.docx", use_container_width=True)

st.caption("ì™„ì „ ë¬´ë£Œ. ì—…ë¡œë“œ/ë¶™ì—¬ë„£ê¸°ë§Œ í•´ë„ ëˆ„ì  í•™ìŠµ â†’ ìš”ì•½ ê°€ì¤‘/í–‰ë™/ì§ˆë¬¸ ë³´ê°•. ë™ì  ì£¼ì œ ë¼ë²¨. UI ë³€ê²½ ì—†ìŒ.")
