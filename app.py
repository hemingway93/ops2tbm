# =========================
# OPS2TBM (AI TextRank + í…œí”Œë¦¿ ìë™ì„ íƒ + ì—­í• ë³„ íŒŒì„œ)
# - í…ìŠ¤íŠ¸ PDF / í…ìŠ¤íŠ¸ ì…ë ¥ ì§€ì›
# - ì´ë¯¸ì§€/ìŠ¤ìº” PDFëŠ” ë¯¸ì§€ì›(ì•ˆë‚´)
# - About(ì‹œì—° ë©˜íŠ¸) ì‚¬ì´ë“œë°” ìœ ì§€
# - í…œí”Œë¦¿: ìë™/ì‚¬ê³ ì‚¬ë¡€í˜•/ê°€ì´ë“œí˜• (ìˆ˜ë™ ì„ íƒ ê°€ëŠ¥)
# =========================

import io
import re
from typing import List, Tuple, Dict

import streamlit as st
from docx import Document
from docx.shared import Pt
from pdfminer.high_level import extract_text as pdf_extract_text
import regex as rxx
import networkx as nx

# ----------------------------
# ì „ì²˜ë¦¬ & ë¬¸ì¥ ì²˜ë¦¬
# ----------------------------
def clean_text(text: str) -> str:
    if not text:
        return ""
    # ë¹„ê°€ì‹œë¬¸ì/ê³µë°± ì •ë¦¬
    text = text.replace("\ufeff", " ")
    text = re.sub(r"[ \t]+", " ", text)
    # í‘œ ìº¡ì…˜/ì¶œì²˜/í˜ì´ì§€ ê¼¬ë¦¬í‘œ ì œê±°(ë„ˆë¬´ ê³µê²©ì ì´ë©´ ì¤„ì´ê±°ë‚˜ ì£¼ì„)
    text = re.sub(r"(ì¶œì²˜|ìë£Œ|ì‘ì„±|í˜ì´ì§€)\s*[:ï¼š].*", "", text, flags=re.IGNORECASE)
    # ì¤‘ë³µ ì¤„ë°”ê¿ˆ ì¶•ì•½
    text = re.sub(r"\n{2,}", "\n", text)
    return text.strip()

def split_sentences_ko(text: str) -> List[str]:
    # ë¬¸ì¥ ê²½ê³„ + ì¤„ë°”ê¿ˆ ê¸°ì¤€
    sents = rxx.split(r"(?<=[\.!?â€¦]|ë‹¤\.|ë‹¤!|ë‹¤\?)\s+|\n", text)
    sents = [s.strip(" -â€¢â—â–ªâ–¶â–·\t") for s in sents if len(s.strip()) > 3]
    return sents

def simple_tokenize_ko(s: str) -> List[str]:
    s = rxx.sub(r"[^0-9A-Za-zê°€-í£]", " ", s)
    return [t for t in s.split() if len(t) >= 2]

STOPWORDS = set(["ê·¸ë¦¬ê³ ","ê·¸ëŸ¬ë‚˜","í•˜ì§€ë§Œ","ë˜ëŠ”","ë˜í•œ","ë“±","ë°","ì´í›„","ì´ì „","ì‚¬ìš©","ê²½ìš°","ê´€ë ¨","ëŒ€í•œ","ìœ„í•´","ìš°ë¦¬","ë“±ì˜","ë“±ì„","í•´ë‹¹"])

def jaccard_sim(a: List[str], b: List[str]) -> float:
    sa, sb = set([t for t in a if t not in STOPWORDS]), set([t for t in b if t not in STOPWORDS])
    if not sa or not sb:
        return 0.0
    inter = len(sa & sb)
    union = len(sa | sb)
    return inter / union if union else 0.0

# ----------------------------
# í‚¤ì›Œë“œ & ìƒìˆ˜
# ----------------------------
KW_OVERVIEW = ["ê°œìš”","ì‚¬ë¡€","ì‚¬ê³ ","ë°°ê²½","ìš”ì•½","í˜„í™©"]
KW_CAUSE    = ["ì›ì¸","ì´ìœ ","ë¬¸ì œì ","ë¶€ì ì •","ë¯¸ë¹„","ìœ„í—˜ìš”ì¸"]
KW_RULES    = ["ì˜ˆë°©","ëŒ€ì±…","ìˆ˜ì¹™","ì ê²€","ì¡°ì¹˜","í™•ì¸","ì¤€ìˆ˜","ê´€ë¦¬","ì„¤ì¹˜","ì°©ìš©","ë°°ì¹˜","í†µì œ"]

KW_GUIDE_CORE = ["ê°€ì´ë“œ","ì•ˆë‚´","ë³´í˜¸","ê±´ê°•","ëŒ€ì‘","ì ˆì°¨","ì§€ì¹¨","ë§¤ë‰´ì–¼","ì˜ˆë°©êµìœ¡","ìƒë‹´","ì§€ì›"]
KW_ROLES      = ["ì‚¬ì—…ì£¼","ê·¼ë¡œì","ë…¸ë™ì","ê³ ê°","ì œ3ì","ê´€ë¦¬ì","ê°ì‹œì","ì±…ì„ì","ë‹´ë‹¹ì"]
KW_FLOW       = ["ëŒ€ì‘ì ˆì°¨","ì ˆì°¨","ì‹ ê³ ","ì¡°ì¹˜","ë³´ê³ ","ìƒë‹´","ì¹˜ë£Œ","íœ´ì‹","ì—…ë¬´ì¤‘ë‹¨","ì „í™˜"]

SAFETY_CONSTANTS = [
    "ì„ ì¡°ì¹˜ í›„ì‘ì—…(ì•ˆì „ì„¤ë¹„Â·ë‚œê°„Â·ë¼ì´í”„ë¼ì¸ ì„¤ì¹˜ í›„ ì‘ì—…)",
    "ê°ì‹œì ë°°ì¹˜ ë° ìœ„í—˜êµ¬ì—­ ì¶œì… í†µì œ",
    "ê°œì¸ë³´í˜¸êµ¬ ì°©ìš©(ì•ˆì „ëª¨Â·ì•ˆì „ë²¨íŠ¸Â·ì•ˆì „í™” ë“±) ì² ì €",
    "ì‘ì—…ê³„íšì„œÂ·ìœ„í—˜ì„±í‰ê°€ ì‚¬ì „ ê²€í†  ë° TBM ê³µìœ ",
    "ì¶”ë½Â·í˜‘ì°© ë“± ê³ ìœ„í—˜ ì‘ì—… ì‹œ ì‘ì—…ì¤‘ì§€ ê¸°ì¤€ ìˆ™ì§€",
]

ROOF_EXTRAS = [
    "íˆ¬ê´‘íŒ(ì¬ë¼ì´íŠ¸) ìœ„ ì ˆëŒ€ ë°Ÿì§€ ì•Šê¸°(ì·¨ì•½ë¶€ í‘œì‹œ)",
    "ì§€ë¶• ì‘ì—… ì‹œ ì•ˆì „ë°œíŒÂ·ë‚œê°„Â·ë¼ì´í”„ë¼ì¸Â·ì¶”ë½ë°©ì§€ë§ ì„¤ì¹˜",
    "ê¸°ìƒ(ê°•í’Â·ìš°ì²œ) ë¶ˆëŸ‰ ì‹œ ì‘ì—… ì¤‘ì§€",
]

# ----------------------------
# ë¶ˆë¦¿/ì—­í• /ì ˆì°¨ íŒŒì„œ
# ----------------------------
BULLET_PAT = r"^[\s]*([\-â€¢â—â–ªâ–¶â–·]|\d+\)|\(\d+\)|\d+\.)\s*(.+)$"

ROLE_HEADERS = [
    ("ì‚¬ì—…ì£¼", ["ì‚¬ì—…ì£¼","ê³ ìš©ì£¼","ê²½ì˜","ê´€ë¦¬ê°ë…ì"]),
    ("ê·¼ë¡œì", ["ê·¼ë¡œì","ë…¸ë™ì","ì‘ì—…ì","ì¢…ì‚¬ì"]),
    ("ê³ ê°",   ["ê³ ê°","ì´ìš©ì","ì œ3ì"]),
]

FLOW_HEADERS = ["ëŒ€ì‘ì ˆì°¨","ì ˆì°¨","ì‹ ê³  ì ˆì°¨","ëŒ€ì‘","ì²˜ë¦¬ ì ˆì°¨"]

def extract_bullets(block: str) -> List[str]:
    out = []
    for line in block.splitlines():
        m = re.match(BULLET_PAT, line.strip())
        if m:
            out.append(m.group(2).strip())
    # ë¶ˆë¦¿ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ë¬¸ì¥ ë‹¨ìœ„ë¡œë¼ë„ ë¶„ë¦¬
    if not out:
        out = [l.strip(" -â€¢â—â–ªâ–¶â–·") for l in block.splitlines() if len(l.strip()) > 2]
    # ë„ˆë¬´ ê¸´ ì¤„ ì»·
    res = []
    for s in out:
        s = re.sub(r"\s{2,}", " ", s)
        if len(s) > 140:
            s = s[:137] + "â€¦"
        res.append(s)
    return res

def extract_role_sections(text: str) -> Dict[str, List[str]]:
    # ë¬¸ì„œì—ì„œ 'ì‚¬ì—…ì£¼', 'ê·¼ë¡œì', 'ê³ ê°'ìœ¼ë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì½œë¡ /ì€/ëŠ” ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ë¸”ëŸ­ì„ ì¶”ì¶œ
    role_map = {k: [] for k,_ in ROLE_HEADERS}
    lines = text.splitlines()
    cur_role = None
    buf = []

    def flush():
        nonlocal buf, cur_role
        if cur_role and buf:
            bullets = extract_bullets("\n".join(buf))
            role_map[cur_role].extend(bullets)
        buf = []

    for line in lines:
        norm = line.strip()
        if not norm:
            continue
        # ì—­í•  í—¤ë” ê°ì§€
        found = None
        for role, keys in ROLE_HEADERS:
            if any(norm.startswith(k) for k in keys) or any((k+"ì€" in norm or k+"ëŠ”" in norm or k+":" in norm) for k in keys):
                found = role
                break
        if found:
            flush()
            cur_role = found
            # í—¤ë” ë¼ì¸ì— ë¶™ì€ ë‚´ìš©ë„ ê°™ì´ ë³´ê´€
            rest = norm
            # ì½œë¡  ì´í›„ë¥¼ ë–¼ì–´ ë‚´ìš©ìœ¼ë¡œ í¬í•¨
            if ":" in rest:
                rest = rest.split(":",1)[1].strip()
                if rest:
                    buf.append(rest)
            continue
        # ì¼ë°˜ ë¼ì¸
        if cur_role:
            buf.append(norm)
    flush()
    # ê³µë°± ì œê±°
    for k in list(role_map.keys()):
        role_map[k] = [s for s in role_map[k] if s]
    return role_map

def extract_flow_section(text: str) -> List[str]:
    # ëŒ€ì‘ì ˆì°¨/ì ˆì°¨ ë“± í‚¤ì›Œë“œ ì¸ê·¼ ë¸”ëŸ­ ì¶”ì¶œ
    lines = text.splitlines()
    buf = []
    capture = False
    got = []
    for ln in lines:
        t = ln.strip()
        if any(h in t for h in FLOW_HEADERS):
            capture = True
            continue
        if capture:
            if t == "" or re.match(r"^\s*[-=]+\s*$", t):
                continue
            # ì„¹ì…˜ì´ ëë‚˜ëŠ” ì‹ í˜¸(ë‹¤ë¥¸ í° í—¤ë”)
            if any(key in t for _,keys in ROLE_HEADERS for key in keys):
                break
            got.append(t)
    if not got:
        return []
    return extract_bullets("\n".join(got))

# ----------------------------
# ê·œì¹™ ê¸°ë°˜ & AI(TextRank) ì¶”ì¶œ
# ----------------------------
def pick_sentences_rule(sents: List[str], keywords: List[str], limit: int) -> List[str]:
    scored = []
    for s in sents:
        score = sum(1 for k in keywords if k in s)
        if score > 0:
            scored.append((score, len(s), s))
    scored.sort(key=lambda x: (-x[0], x[1]))
    return [s for _, _, s in scored[:limit]]

def textrank_scores(sents: List[str]) -> List[float]:
    if not sents:
        return []
    tokens = [simple_tokenize_ko(s) for s in sents]
    g = nx.Graph()
    g.add_nodes_from(range(len(sents)))
    for i in range(len(sents)):
        for j in range(i+1, len(sents)):
            w = jaccard_sim(tokens[i], tokens[j])
            if w > 0:
                g.add_edge(i, j, weight=w)
    if g.number_of_edges() == 0:
        return [1.0] * len(sents)
    pr = nx.pagerank(g, weight="weight")
    return [pr.get(i, 0.0) for i in range(len(sents))]

def pick_sentences_tr(sents: List[str], kw: List[str], limit: int, scores: List[float]) -> List[str]:
    ranked = []
    for idx, s in enumerate(sents):
        kscore = 1 + sum(1 for k in kw if k in s) * 0.3
        ranked.append((scores[idx] * kscore, len(s), s))
    ranked.sort(key=lambda x: (-x[0], x[1]))
    return [s for _, _, s in ranked[:limit]]

# ----------------------------
# í…œí”Œë¦¿ ìë™ ì„ íƒ
# ----------------------------
def detect_template(text: str) -> str:
    # ì—­í• /ê°€ì´ë“œ ì‹ í˜¸ê°€ ë§ìœ¼ë©´ 'guide', ì•„ë‹ˆë©´ 'accident'
    t = text
    role_hits = sum(t.count(k) for _, keys in ROLE_HEADERS for k in keys)
    guide_hits = sum(t.count(k) for k in (KW_GUIDE_CORE + KW_FLOW))
    accident_hits = sum(t.count(k) for k in (KW_OVERVIEW + KW_CAUSE + KW_RULES))
    if role_hits + guide_hits > accident_hits * 0.8:
        return "guide"
    return "accident"

# ----------------------------
# TBM ìƒì„±(ì‚¬ê³ ì‚¬ë¡€í˜• / ê°€ì´ë“œí˜•)
# ----------------------------
def make_tbm_script_accident(raw_text: str, use_ai: bool) -> Tuple[str, dict]:
    text = clean_text(raw_text)
    sents = split_sentences_ko(text)
    if use_ai:
        scores = textrank_scores(sents)
        overview = pick_sentences_tr(sents, KW_OVERVIEW, 3, scores)
        causes   = pick_sentences_tr(sents, KW_CAUSE,   4, scores)
        rules    = pick_sentences_tr(sents, KW_RULES,   6, scores)
    else:
        overview = pick_sentences_rule(sents, KW_OVERVIEW, 3)
        causes   = pick_sentences_rule(sents, KW_CAUSE,   4)
        rules    = pick_sentences_rule(sents, KW_RULES,   6)
    if len(rules) < 4:
        rules = rules + SAFETY_CONSTANTS[: (4 - len(rules)) + 1]
    rules = rules[:6]
    # íƒ€ì´í‹€ ì¶”ì •
    title = "OPS ê¸°ë°˜ ì•ˆì „ TBM"
    for cand in sents[:5]:
        if any(k in cand for k in ["ì§€ë¶•","ì¶”ë½","ì§ˆì‹","í™”ì¬","í˜‘ì°©","ê°ì „","ì§ˆí™˜","ìœ í•´","ì¤‘ë…"]):
            title = cand.strip(" .")
            if len(title) > 22:
                title = title[:20] + "â€¦"
            break
    closing = [
        "â€˜ì ê¹ì´ë©´ ë¼â€™ëŠ” ê°€ì¥ ìœ„í—˜í•œ ë§ì…ë‹ˆë‹¤. ì• ë§¤í•˜ë©´ ë©ˆì¶”ê³  ì ê²€í•©ì‹œë‹¤.",
        "ì˜¤ëŠ˜ ì‘ì—… ì „, ì·¨ì•½ë¶€Â·ì•ˆì „ì„¤ë¹„Â·PPEÂ·ê°ì‹œì ì—¬ë¶€ë¥¼ ë‹¤ì‹œ í™•ì¸í•©ì‹œë‹¤.",
    ]
    chant = "í•œ ë²ˆ ë” ì ê²€! ëª¨ë‘ê°€ ì•ˆì „!"
    # ìŠ¤í¬ë¦½íŠ¸ í•©ì„±
    lines = []
    lines.append(f"ğŸ¦º TBM ëŒ€ë³¸ â€“ ã€Œ{title}ã€\n")
    lines.append("â— ì¸ì‚¬ ë° ë„ì…\n- OPS ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¬í•´ ìœ„í—˜ìš”ì¸ì„ ì§šê³ , ìš°ë¦¬ í˜„ì¥ì—ì„œ ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆëŠ” ì•ˆì „ìˆ˜ì¹™ì„ ê³µìœ í•©ë‹ˆë‹¤.\n")
    lines.append("â— 1. ì‚¬ê³  ê°œìš”")
    for s in (overview or ["(OPSì—ì„œ ê°œìš”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ ê°œìš”ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.)"]):
        lines.append(f"- {s}")
    lines.append("\nâ— 2. ì‚¬ê³  ì›ì¸")
    for s in (causes or ["ì‘ì—…ê³„íš ë¶€ì¬","ë³´í˜¸êµ¬ ë¯¸ì°©ìš©","ê°ì‹œì ë¶€ì¬"]):
        lines.append(f"- {s}")
    lines.append("\nâ— 3. ì£¼ìš” ì•ˆì „ìˆ˜ì¹™(ìš°ë¦¬ í˜„ì¥ ì ìš©)")
    for s in rules:
        lines.append(f"- {s}")
    if any(k in text for k in ["ì§€ë¶•","ì¬ë¼ì´íŠ¸","íˆ¬ê´‘íŒ","ì¶”ë½"]):
        for s in ROOF_EXTRAS:
            lines.append(f"- {s}")
    lines.append("\nâ— 4. ë§ˆë¬´ë¦¬ ë‹¹ë¶€")
    for s in closing:
        lines.append(f"- {s}")
    lines.append("\nâ— ë§ˆë¬´ë¦¬ êµ¬í˜¸")
    lines.append(f"- {chant}")
    script = "\n".join(lines).strip()
    parts = {"title": title,"overview": overview,"causes": causes,"rules": rules,"closing": closing,"chant": chant}
    return script, parts

def make_tbm_script_guide(raw_text: str, use_ai: bool) -> Tuple[str, dict]:
    text = clean_text(raw_text)
    sents = split_sentences_ko(text)
    # í•µì‹¬ ë©”ì‹œì§€(ìš”ì•½)
    if use_ai:
        scores = textrank_scores(sents)
        core = pick_sentences_tr(sents, KW_GUIDE_CORE, 3, scores)
    else:
        core = pick_sentences_rule(sents, KW_GUIDE_CORE, 3)
    # ì—­í• ë³„ íŒŒì‹±
    roles = extract_role_sections(text)  # {"ì‚¬ì—…ì£¼":[...], "ê·¼ë¡œì":[...], "ê³ ê°":[...]}
    # ëŒ€ì‘ì ˆì°¨
    flow = extract_flow_section(text)
    # ë³´ê°•: ì—­í• /ì ˆì°¨ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê·œì¹™/ìƒìˆ˜ë¡œ ë©”ìš°ê¸°
    if sum(len(v) for v in roles.values()) == 0:
        # í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œë¼ë„ ê·œì¹™ ì¶”ì¶œ
        rules_guess = pick_sentences_rule(sents, KW_RULES + KW_GUIDE_CORE, 6)
        if not rules_guess:
            rules_guess = SAFETY_CONSTANTS[:4]
        # ì—­í•  ê³µí†µ ì„¹ì…˜ìœ¼ë¡œ í•©ì¹˜ê¸°
        roles["ì‚¬ì—…ì£¼"] = [s for s in rules_guess[:2]]
        roles["ê·¼ë¡œì"] = [s for s in rules_guess[2:4]]
        roles["ê³ ê°"]   = [s for s in rules_guess[4:6] or ["ìƒí˜¸ ì¡´ì¤‘ê³¼ ë°°ë ¤ ì‹¤ì²œ"]]
    if not flow:
        flow = ["ìƒí™© ì¸ì§€ ì¦‰ì‹œ ë³´ê³  ë° ê¸°ë¡", "ì—…ë¬´ ì¼ì‹œì¤‘ë‹¨Â·íœ´ì‹ ë¶€ì—¬", "í•„ìš” ì‹œ ìƒë‹´Â·ì¹˜ë£Œ ì§€ì› ì—°ê³„", "ì¬ë°œë°©ì§€ ëŒ€ì±… ìˆ˜ë¦½ ë° ê³µìœ "]
    # íƒ€ì´í‹€
    title = "OPS ê¸°ë°˜ ì•ˆì „ TBM(ê°€ì´ë“œ)"
    for cand in sents[:5]:
        if any(k in cand for k in ["ê°ì •ë…¸ë™","ê±´ê°•ë³´í˜¸","ëŒ€ì‘ì§€ì¹¨","ê³ ê°ì‘ëŒ€","í­ì–¸","í­í–‰","ì •ì‹ ê±´ê°•"]):
            title = cand.strip(" .")
            if len(title) > 22:
                title = title[:20] + "â€¦"
            break
    closing = [
        "í˜„ì¥ì˜ ê·œì •Â·ì ˆì°¨ë¥¼ ë”°ë¥´ê³ , ì• ë§¤í•˜ë©´ ì¦‰ì‹œ ë³´ê³ Â·ì¤‘ì§€í•©ë‹ˆë‹¤.",
        "ì„œë¡œë¥¼ ì¡´ì¤‘í•˜ëŠ” ë§ê³¼ íƒœë„ê°€ ì•ˆì „ë³´ê±´ì˜ ì¶œë°œì ì…ë‹ˆë‹¤.",
    ]
    chant = "ì¡´ì¤‘ê³¼ ë°°ë ¤, ì•ˆì „ì˜ ê¸°ë³¸!"
    # ìŠ¤í¬ë¦½íŠ¸ í•©ì„±(ê°€ì´ë“œí˜•)
    lines = []
    lines.append(f"ğŸ¦º TBM ëŒ€ë³¸ â€“ ã€Œ{title}ã€\n")
    lines.append("â— ì¸ì‚¬ ë° ë„ì…\n- OPS ê°€ì´ë“œì˜ í•µì‹¬ì„ í˜„ì¥ì—ì„œ ë°”ë¡œ ì ìš©í•  ìˆ˜ ìˆë„ë¡ ìš”ì•½í•´ ê³µìœ í•©ë‹ˆë‹¤.\n")
    lines.append("â— í•µì‹¬ ë©”ì‹œì§€")
    for s in (core or ["í˜„ì¥ì˜ ì•ˆì „Â·ê±´ê°•ë³´í˜¸ë¥¼ ìœ„í•´ ì—­í• ë³„ ì¡°ì¹˜ì™€ ëŒ€ì‘ì ˆì°¨ë¥¼ ì¤€ìˆ˜í•©ë‹ˆë‹¤."]):
        lines.append(f"- {s}")
    # ì—­í• ë³„
    for role in ["ì‚¬ì—…ì£¼","ê·¼ë¡œì","ê³ ê°"]:
        if roles.get(role):
            lines.append(f"\nâ— {role} ìˆ˜ì¹™")
            for s in roles[role][:6]:
                lines.append(f"- {s}")
    # ëŒ€ì‘ì ˆì°¨
    lines.append("\nâ— ëŒ€ì‘ì ˆì°¨")
    for s in flow[:8]:
        lines.append(f"- {s}")
    # ë§ˆë¬´ë¦¬
    lines.append("\nâ— ë§ˆë¬´ë¦¬ ë‹¹ë¶€")
    for s in closing:
        lines.append(f"- {s}")
    lines.append("\nâ— ë§ˆë¬´ë¦¬ êµ¬í˜¸")
    lines.append(f"- {chant}")
    script = "\n".join(lines).strip()
    parts = {"title": title,"core": core,"roles": roles,"flow": flow,"closing": closing,"chant": chant}
    return script, parts

# ----------------------------
# ë‚´ë³´ë‚´ê¸°
# ----------------------------
def to_txt_bytes(text: str) -> bytes:
    return text.encode("utf-8")

def to_docx_bytes(text: str) -> bytes:
    doc = Document()
    style = doc.styles['Normal']
    style.font.name = 'Malgun Gothic'
    style.font.size = Pt(11)
    for line in text.split("\n"):
        doc.add_paragraph(line)
    buf = io.BytesIO()
    doc.save(buf)
    buf.seek(0)
    return buf.read()

# ----------------------------
# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
# ----------------------------
def extract_text_from_pdf(file_bytes: bytes) -> str:
    try:
        return pdf_extract_text(io.BytesIO(file_bytes)) or ""
    except Exception:
        return ""

# ----------------------------
# ìƒ˜í”Œ í…ìŠ¤íŠ¸ (ì‚¬ê³ /ê°€ì´ë“œ 2ì¢…)
# ----------------------------
SAMPLE_ACCIDENT = """2020ë…„ 2ì›”, ì§€ë¶• ì¬ë¼ì´íŠ¸ ìœ„ì—ì„œ ì‘ì—… ì¤‘ ì¶”ë½ ì¬í•´ê°€ ë°œìƒ. FRP íˆ¬ê´‘íŒì˜ ë…¸í›„ë¡œ íŒŒì† ìœ„í—˜ì´ ë†’ìŒ.
ì‘ì—…ê³„íš ë¯¸í¡, ì¶”ë½ë°©ì§€ì„¤ë¹„ ë¯¸ì„¤ì¹˜, ê°ì‹œì ë¶€ì¬ê°€ ì£¼ìš” ì›ì¸.
ì˜ˆë°©ì„ ìœ„í•´ ì•ˆì „ë°œíŒ/ë‚œê°„/ë¼ì´í”„ë¼ì¸ ì„¤ì¹˜, ì·¨ì•½ë¶€ í‘œì‹œ ë° ì¶œì…í†µì œ, ê°ì‹œì ë°°ì¹˜ í•„ìš”."""

SAMPLE_GUIDE = """ê°ì •ë…¸ë™ ê·¼ë¡œì ê±´ê°•ë³´í˜¸ ì•ˆë‚´. ê³ ê°ì˜ í­ì–¸Â·í­í–‰ ë“±ìœ¼ë¡œ ì¸í•œ ê±´ê°•ì¥í•´ ì˜ˆë°©ê³¼ ëŒ€ì‘ì ˆì°¨ë¥¼ ì œì‹œ.
ì‚¬ì—…ì£¼ëŠ” ê³ ê°ì‘ëŒ€ì—…ë¬´ ì§€ì¹¨ ë§ˆë ¨ê³¼ ì˜ˆë°©êµìœ¡, ìƒë‹´Â·ì¹˜ë£Œ ì§€ì›ì„ í•´ì•¼ í•¨.
ê·¼ë¡œìëŠ” ê±´ê°•ì¥í•´ ë°œìƒ ìš°ë ¤ ì‹œ ì¡°ì¹˜ë¥¼ ìš”êµ¬í•  ìˆ˜ ìˆìŒ.
ê³ ê°ì€ ë°˜ë§Â·ìš•ì„¤Â·ë¬´ë¦¬í•œ ìš”êµ¬ë¥¼ ìì œí•˜ê³  ì¡´ì¤‘í•´ì•¼ í•¨.
í­ì–¸ ë°œìƒ ì‹œ ëŒ€ì‘ì ˆì°¨: ì¤‘ì§€ ìš”ì²­ â†’ ì±…ì„ì ë³´ê³  â†’ ê¸°ë¡/ì¦ê±° í™•ë³´ â†’ íœ´ì‹/ìƒë‹´Â·ì¹˜ë£Œ ì§€ì› â†’ ì¬ë°œë°©ì§€ ëŒ€ì±… ìˆ˜ë¦½."""

# ----------------------------
# UI
# ----------------------------
st.set_page_config(page_title="OPS2TBM", page_icon="ğŸ¦º", layout="wide")

# Sidebar: About / ì‹œì—° ë©˜íŠ¸
with st.sidebar:
    st.header("â„¹ï¸ ì†Œê°œ / ì‹œì—° ë©˜íŠ¸")
    st.markdown("""
**ë¬¸ì œ**  
OPS ë¬¸ì„œë¥¼ í˜„ì¥ TBM ëŒ€ë³¸ìœ¼ë¡œ ë°”ë¡œ ì“°ê¸° ì–´ë µìŠµë‹ˆë‹¤.

**í•´ê²°**  
ë¬¸ì„œ ë‚´ìš©ì„ ìë™ ë¶„ì„í•˜ì—¬,  
- **ì‚¬ê³ ì‚¬ë¡€í˜•**(ê°œìš”/ì›ì¸/ìˆ˜ì¹™) ë˜ëŠ”  
- **ê°€ì´ë“œí˜•**(í•µì‹¬/ì—­í• ë³„ ìˆ˜ì¹™/ëŒ€ì‘ì ˆì°¨)  
TBMìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

**ì‹œì—° íë¦„**  
1) íŒŒì¼ ì—…ë¡œë“œ(í…ìŠ¤íŠ¸ PDF) ë˜ëŠ” í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°  
2) **ëª¨ë“œ ì„ íƒ: ê¸°ë³¸/AI(TextRank)** + **í…œí”Œë¦¿(ìë™/ìˆ˜ë™)**  
3) ëŒ€ë³¸ ìƒì„± â†’ ì„¹ì…˜ë³„ í™•ì¸  
4) `.docx` ë‹¤ìš´ë¡œë“œ

**í˜„ì¬ ë²„ì „**  
- OCR ë¯¸í¬í•¨(í´ë¼ìš°ë“œ ì•ˆì •í™”) â†’ ìŠ¤ìº”ë³¸ì€ í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸° ì‚¬ìš©  
- ğŸ”¹ AI: TextRank ìš”ì•½(ê·¸ë˜í”„ ê¸°ë°˜ ë¬¸ì¥ ë­í‚¹)
""")

st.title("ğŸ¦º OPS2TBM â€” OPS/í¬ìŠ¤í„°ë¥¼ TBM ëŒ€ë³¸ìœ¼ë¡œ ìë™ ë³€í™˜")

st.markdown("""
**ì‚¬ìš©ë²•**  
1) **í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ PDF ì—…ë¡œë“œ** ë˜ëŠ” **OPS í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°**  
2) **ëª¨ë“œ(ê¸°ë³¸/AI)** ì™€ **í…œí”Œë¦¿(ìë™/ì‚¬ê³ ì‚¬ë¡€í˜•/ê°€ì´ë“œí˜•)** ì„ íƒ  
3) **TBM ëŒ€ë³¸ ìƒì„±** â†’ **.txt / .docx** ë‹¤ìš´ë¡œë“œ

> âš ï¸ ì´ë¯¸ì§€/ìŠ¤ìº” PDFëŠ” í˜„ì¬ OCR ë¯¸ì§€ì›ì…ë‹ˆë‹¤. ê·¸ ê²½ìš° í…ìŠ¤íŠ¸ë¥¼ ë¶™ì—¬ë„£ì–´ ì£¼ì„¸ìš”.
""")

col1, col2 = st.columns([1, 1])

with col1:
    uploaded = st.file_uploader("OPS íŒŒì¼ ì—…ë¡œë“œ (PDFë§Œ ì§€ì›)", type=["pdf"])
    manual_text = st.text_area("ë˜ëŠ” OPS í…ìŠ¤íŠ¸ ì§ì ‘ ë¶™ì—¬ë„£ê¸°", height=180, placeholder="OPS ë³¸ë¬¸ì„ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”...")

    c1, c2, c3 = st.columns(3)
    with c1:
        if st.button("ì‚¬ê³  ìƒ˜í”Œ", use_container_width=True):
            manual_text = SAMPLE_ACCIDENT
    with c2:
        if st.button("ê°€ì´ë“œ ìƒ˜í”Œ", use_container_width=True):
            manual_text = SAMPLE_GUIDE
    with c3:
        st.write("")

    extracted = ""
    if uploaded:
        with st.spinner("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘... (í…ìŠ¤íŠ¸ PDFë§Œ ì§€ì›)"):
            data = uploaded.read()
            extracted = extract_text_from_pdf(data)
            if not extracted.strip():
                st.warning("ì´ PDFëŠ” **ì´ë¯¸ì§€/ìŠ¤ìº”**ì¼ ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤. ìš°ì¸¡ì˜ í…ìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ ì§„í–‰í•´ ì£¼ì„¸ìš”.")

    base_text = manual_text.strip() if manual_text.strip() else extracted.strip()

    st.markdown("**ì¶”ì¶œ/ì…ë ¥ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°**")
    edited_text = st.text_area("í…ìŠ¤íŠ¸", value=base_text, height=240)

with col2:
    use_ai = st.toggle("ğŸ”¹ AI ìš”ì•½ ëª¨ë“œ(TextRank) ì¼œê¸°", value=True)
    template_mode = st.selectbox("ğŸ§© í…œí”Œë¦¿ ì„ íƒ", ["ìë™ ì„ íƒ","ì‚¬ê³ ì‚¬ë¡€í˜•","ê°€ì´ë“œí˜•"])

    if st.button("ğŸ› ï¸ TBM ëŒ€ë³¸ ìƒì„±", type="primary", use_container_width=True):
        if not edited_text.strip():
            st.warning("í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. PDF ì—…ë¡œë“œ(í…ìŠ¤íŠ¸ PDF) ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ í›„ ì‹œë„í•˜ì„¸ìš”.")
        else:
            # í…œí”Œë¦¿ ê²°ì •
            if template_mode == "ìë™ ì„ íƒ":
                detected = detect_template(edited_text)
            elif template_mode == "ì‚¬ê³ ì‚¬ë¡€í˜•":
                detected = "accident"
            else:
                detected = "guide"

            if detected == "accident":
                script, parts = make_tbm_script_accident(edited_text, use_ai=use_ai)
                subtitle = "ì‚¬ê³ ì‚¬ë¡€í˜• í…œí”Œë¦¿ ì ìš©"
            else:
                script, parts = make_tbm_script_guide(edited_text, use_ai=use_ai)
                subtitle = "ê°€ì´ë“œí˜• í…œí”Œë¦¿ ì ìš©"

            st.success(f"ëŒ€ë³¸ ìƒì„± ì™„ë£Œ! ({subtitle})")
            st.text_area("TBM ëŒ€ë³¸", value=script, height=420)

            c1, c2 = st.columns(2)
            with c1:
                st.download_button("â¬‡ï¸ .txt ë‹¤ìš´ë¡œë“œ", data=script.encode("utf-8"),
                                   file_name="tbm_script.txt", use_container_width=True)
            with c2:
                docx_bytes = to_docx_bytes(script)
                st.download_button("â¬‡ï¸ .docx ë‹¤ìš´ë¡œë“œ", data=docx_bytes,
                                   file_name="tbm_script.docx", use_container_width=True)

st.caption("í˜„ì¬: ê·œì¹™ + TextRank ê¸°ë°˜(ê²½ëŸ‰ AI). í…œí”Œë¦¿ ìë™/ìˆ˜ë™. ë‹¤ìŒ ë‹¨ê³„: OCR ì¬ë„ì…Â·LLM ë¯¸ì„¸ë‹¤ë“¬ê¸°.")
