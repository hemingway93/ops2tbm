# =========================
# OPS2TBM (Stable UI + Pure NumPy TextRank)
# - í…ìŠ¤íŠ¸ PDF / í…ìŠ¤íŠ¸ ì…ë ¥ ì§€ì›
# - ì´ë¯¸ì§€/ìŠ¤ìº” PDFëŠ” ë¯¸ì§€ì›(ì•ˆë‚´)
# - Sidebarì— ì†Œê°œ/ì‚¬ìš©ë²•/ì‹œì—° ë©˜íŠ¸ í‘œì‹œ
# - í…œí”Œë¦¿: ìë™/ì‚¬ê³ ì‚¬ë¡€í˜•/ê°€ì´ë“œí˜•
# - AI ìš”ì•½: ìˆœìˆ˜ NumPy TextRank (ì„¤ì¹˜ ì´ìŠˆ ç„¡)
# =========================

import io
from typing import List, Tuple, Dict

import streamlit as st
from docx import Document
from docx.shared import Pt
from pdfminer.high_level import extract_text as pdf_extract_text
import pypdfium2 as pdfium
import numpy as np
import regex as rxx

# ----------------------------
# ê³µí†µ ìœ í‹¸
# ----------------------------
def normalize_text(text: str) -> str:
    text = text.replace("\x0c", "\n")
    text = rxx.sub(r"[ \t]+\n", "\n", text)
    text = rxx.sub(r"\n{3,}", "\n\n", text)
    return text.strip()

def read_pdf_text(file_bytes: bytes) -> str:
    # 1) pdfminerë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    try:
        with io.BytesIO(file_bytes) as bio:
            text = pdf_extract_text(bio) or ""
    except Exception:
        text = ""
    text = normalize_text(text)

    # 2) í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ìœ¼ë©´(ì´ë¯¸ì§€ PDF ì¶”ì •) í˜ì´ì§€ ìˆ˜ ì²´í¬ í›„ ì•ˆë‚´
    if len(text.strip()) < 10:
        try:
            with io.BytesIO(file_bytes) as bio:
                pdf = pdfium.PdfDocument(bio)
                pages = len(pdf)
            if pages > 0 and not text.strip():
                st.warning("ì´ PDFëŠ” ì´ë¯¸ì§€/ìŠ¤ìº” ê¸°ë°˜ìœ¼ë¡œ ë³´ì—¬ìš”. í˜„ì¬ ë²„ì „ì€ OCR ì—†ì´ 'í…ìŠ¤íŠ¸'ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        except Exception:
            pass
    return text

def split_sentences_ko(text: str) -> List[str]:
    raw = rxx.split(r"(?<=[\.!\?]|ë‹¤\.)\s+|\n+", text)
    return [s.strip() for s in raw if s and len(s.strip()) > 1]

def simple_tokens(s: str) -> List[str]:
    s = s.lower()
    return rxx.findall(r"[ê°€-í£a-z0-9]{2,}", s)

# ----------------------------
# ìˆœìˆ˜ NumPy TextRank
# ----------------------------
def sentence_tfidf_vectors(sents: List[str]) -> Tuple[np.ndarray, List[str]]:
    toks_list = [simple_tokens(s) for s in sents]
    vocab: Dict[str, int] = {}
    for toks in toks_list:
        for t in toks:
            if t not in vocab:
                vocab[t] = len(vocab)
    if not vocab:
        return np.zeros((len(sents), 0), dtype=np.float32), []
    mat = np.zeros((len(sents), len(vocab)), dtype=np.float32)
    df = np.zeros((len(vocab),), dtype=np.float32)
    for i, toks in enumerate(toks_list):
        for t in toks:
            j = vocab[t]
            mat[i, j] += 1.0
        for t in set(toks):
            df[vocab[t]] += 1.0
    N = float(len(sents))
    idf = np.log((N + 1.0) / (df + 1.0)) + 1.0
    mat *= idf
    norms = np.linalg.norm(mat, axis=1, keepdims=True) + 1e-8
    mat = mat / norms
    return mat, list(vocab.keys())

def cosine_sim_matrix(X: np.ndarray) -> np.ndarray:
    if X.size == 0:
        return np.zeros((X.shape[0], X.shape[0]), dtype=np.float32)
    sim = np.clip(X @ X.T, 0.0, 1.0)
    np.fill_diagonal(sim, 0.0)
    return sim

def textrank_scores(sents: List[str], d: float = 0.85, max_iter: int = 50, tol: float = 1e-4) -> List[float]:
    if len(sents) == 0:
        return []
    if len(sents) == 1:
        return [1.0]
    X, _ = sentence_tfidf_vectors(sents)
    W = cosine_sim_matrix(X)
    row_sums = W.sum(axis=1, keepdims=True)
    P = np.divide(W, row_sums, out=np.zeros_like(W), where=row_sums > 0)

    n = W.shape[0]
    r = np.ones((n, 1), dtype=np.float32) / n
    teleport = np.ones((n, 1), dtype=np.float32) / n

    for _ in range(max_iter):
        r_new = d * (P.T @ r) + (1 - d) * teleport
        if np.linalg.norm(r_new - r, ord=1) < tol:
            r = r_new
            break
        r = r_new
    return [float(v) for v in r.flatten()]

# ----------------------------
# ì„ íƒ ë¡œì§ (ê·œì¹™/AI)
# ----------------------------
def pick_rule(sents: List[str], keywords: List[str], limit: int) -> List[str]:
    hits = [s for s in sents if any(k in s for k in keywords)]
    if len(hits) >= limit:
        return hits[:limit]
    remain = [s for s in sents if s not in hits]
    remain = sorted(remain, key=lambda x: (-len(x), sents.index(x)))
    return hits + remain[: max(0, limit - len(hits))]

def pick_tr(sents: List[str], keywords: List[str], limit: int, scores: List[float]) -> List[str]:
    if not sents:
        return []
    w = np.array(scores, dtype=np.float32)
    if keywords:
        for i, s in enumerate(sents):
            if any(k in s for k in keywords):
                w[i] += 0.2
    idx = np.argsort(-w)[:limit]
    return [sents[i] for i in idx]

# ----------------------------
# í…œí”Œë¦¿/í‚¤ì›Œë“œ
# ----------------------------
# ê°€ì´ë“œí˜•
KW_GUIDE_CORE = ["ê°€ì´ë“œ", "ì•ˆë‚´", "ë³´í˜¸", "ê±´ê°•", "ëŒ€ì‘", "ì ˆì°¨", "ì§€ì¹¨", "ë§¤ë‰´ì–¼", "ì˜ˆë°©", "ìƒë‹´", "ì§€ì›"]
KW_GUIDE_STEP = ["ì ˆì°¨", "ìˆœì„œ", "ë°©ë²•", "ì ê²€", "í™•ì¸", "ë³´ê³ ", "ì¡°ì¹˜"]
KW_GUIDE_QA   = ["ì§ˆë¬¸", "ì™œ", "ì–´ë–»ê²Œ", "ë¬´ì—‡", "ì£¼ì˜"]

# ì‚¬ê³ ì‚¬ë¡€í˜•
KW_ACC_CORE = ["ì‚¬ê³ ", "ì¬í•´", "ìœ„í—˜", "ì›ì¸", "ì˜ˆë°©", "ëŒ€ì±…", "ë…¸í›„", "ì¶”ë½", "í˜‘ì°©", "ê°ì „", "í™”ì¬"]
KW_ACC_STEP = ["ë°œìƒ", "ê²½ìœ„", "ì¡°ì¹˜", "ê°œì„ ", "êµìœ¡", "ì„¤ì¹˜", "ë°°ì¹˜"]
KW_ACC_QA   = ["ì›ì¸ì€", "ë‹¤ìŒì—ëŠ”", "ì˜ˆë°©í•˜ë ¤ë©´", "í™•ì¸í•  ì ", "ì²´í¬"]

def detect_template(text: str) -> str:
    g_hits = sum(text.count(k) for k in (KW_GUIDE_CORE + KW_GUIDE_STEP))
    a_hits = sum(text.count(k) for k in (KW_ACC_CORE + KW_ACC_STEP))
    return "ê°€ì´ë“œí˜•" if g_hits >= a_hits else "ì‚¬ê³ ì‚¬ë¡€í˜•"

# ----------------------------
# TBM ìƒì„±
# ----------------------------
def make_tbm_guide(text: str, use_ai: bool) -> Tuple[str, Dict[str, List[str]]]:
    sents = split_sentences_ko(text)
    if use_ai:
        scores = textrank_scores(sents)
        core = pick_tr(sents, KW_GUIDE_CORE, 3, scores)
    else:
        core = pick_rule(sents, KW_GUIDE_CORE, 3)
    steps = pick_rule(sents, KW_GUIDE_STEP, 5)
    qa    = pick_rule(sents, KW_GUIDE_QA,   3)

    parts = {"í•µì‹¬": core, "ì ˆì°¨": steps, "ì§ˆë¬¸": qa}
    lines = []
    lines.append("ğŸ¦º TBM ëŒ€ë³¸ â€“ ê°€ì´ë“œí˜•")
    lines.append("")
    lines.append("â— ì˜¤ëŠ˜ì˜ í•µì‹¬ í¬ì¸íŠ¸")
    for s in core: lines.append(f"- {s}")
    lines.append("")
    lines.append("â— ì‘ì—… ì „ ì ˆì°¨/ì ê²€")
    for s in steps: lines.append(f"- {s}")
    lines.append("")
    lines.append("â— í˜„ì¥ í† ì˜ ì§ˆë¬¸")
    for s in qa: lines.append(f"- {s}")
    lines.append("")
    lines.append("â— ë§ˆë¬´ë¦¬ ë©˜íŠ¸")
    lines.append("- â€œì˜¤ëŠ˜ ì‘ì—…ì˜ í•µì‹¬ì€ ìœ„ ì„¸ ê°€ì§€ì…ë‹ˆë‹¤. ë‹¤ ê°™ì´ í™•ì¸í•˜ê³  ì‹œì‘í•©ì‹œë‹¤.â€")
    lines.append("- â€œì ê¹ì´ë¼ë„ ì´ìƒí•˜ë©´ ë°”ë¡œ ì¤‘ì§€í•˜ê³ , ê´€ë¦¬ìì—ê²Œ ì•Œë¦½ë‹ˆë‹¤.â€")
    script = "\n".join(lines)
    return script, parts

def make_tbm_accident(text: str, use_ai: bool) -> Tuple[str, Dict[str, List[str]]]:
    sents = split_sentences_ko(text)
    if use_ai:
        scores = textrank_scores(sents)
        core = pick_tr(sents, KW_ACC_CORE, 3, scores)
    else:
        core = pick_rule(sents, KW_ACC_CORE, 3)
    steps = pick_rule(sents, KW_ACC_STEP, 5)
    qa    = pick_rule(sents, KW_ACC_QA,   3)

    parts = {"í•µì‹¬": core, "ì‚¬ê³ /ì¡°ì¹˜": steps, "ì§ˆë¬¸": qa}
    lines = []
    lines.append("ğŸ¦º TBM ëŒ€ë³¸ â€“ ì‚¬ê³ ì‚¬ë¡€í˜•")
    lines.append("")
    lines.append("â— ì‚¬ê³ /ìœ„í—˜ ìš”ì¸ ìš”ì•½")
    for s in core:  lines.append(f"- {s}")
    lines.append("")
    lines.append("â— ë°œìƒ ê²½ìœ„/ì¡°ì¹˜/ê°œì„ ")
    for s in steps: lines.append(f"- {s}")
    lines.append("")
    lines.append("â— ì¬ë°œ ë°©ì§€ í† ì˜ ì§ˆë¬¸")
    for s in qa:    lines.append(f"- {s}")
    lines.append("")
    lines.append("â— ë§ˆë¬´ë¦¬ ë©˜íŠ¸")
    lines.append("- â€œì´ ì‚¬ë¡€ì—ì„œ ë°°ìš´ ì˜ˆë°© í¬ì¸íŠ¸ë¥¼ ì˜¤ëŠ˜ ì‘ì—…ì— ë°”ë¡œ ì ìš©í•©ì‹œë‹¤.â€")
    lines.append("- â€œê°ì ë§¡ì€ ê³µì •ì—ì„œ ë™ì¼ ìœ„í—˜ì´ ì—†ëŠ”ì§€ ë‹¤ì‹œ ì ê²€í•´ ì£¼ì„¸ìš”.â€")
    script = "\n".join(lines)
    return script, parts

# ----------------------------
# ë‚´ë³´ë‚´ê¸°
# ----------------------------
def to_docx_bytes(script: str) -> bytes:
    doc = Document()
    style = doc.styles["Normal"]
    style.font.name = "Malgun Gothic"
    style.font.size = Pt(11)
    for line in script.split("\n"):
        p = doc.add_paragraph(line)
        for run in p.runs:
            run.font.name = "Malgun Gothic"
            run.font.size = Pt(11)
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio.read()

# ----------------------------
# UI êµ¬ì„± (ì˜ˆì „ ëŠë‚Œìœ¼ë¡œ ë³µì›)
# ----------------------------
st.set_page_config(page_title="OPS2TBM", page_icon="ğŸ¦º", layout="wide")

with st.sidebar:
    st.header("â„¹ï¸ ì†Œê°œ / ì‚¬ìš©ë²•")
    st.markdown("""
**ì´ ì•±ì€ ë¬´ì—‡ì„ í•˜ë‚˜ìš”?**  
OPS ë¬¸ì„œ(í…ìŠ¤íŠ¸ PDF/ë³¸ë¬¸ í…ìŠ¤íŠ¸)ë¥¼ ë„£ìœ¼ë©´,  
- **ì‚¬ê³ ì‚¬ë¡€í˜•** ë˜ëŠ” **ê°€ì´ë“œí˜•** í…œí”Œë¦¿ìœ¼ë¡œ  
- í˜„ì¥ì—ì„œ ë°”ë¡œ ì½ì„ ìˆ˜ ìˆëŠ” **TBM ëŒ€ë³¸**ì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**  
1) ì¢Œì¸¡ì— **íŒŒì¼ ì—…ë¡œë“œ**(í…ìŠ¤íŠ¸ PDF) ë˜ëŠ” **í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°**  
2) ìš°ì¸¡ì—ì„œ **AI ìš”ì•½ (TextRank) í† ê¸€**ê³¼ **í…œí”Œë¦¿(ìë™/ìˆ˜ë™)** ì„ íƒ  
3) **ëŒ€ë³¸ ìƒì„±** â†’ ë¯¸ë¦¬ë³´ê¸° í™•ì¸ â†’ **TXT/DOCX ë‹¤ìš´ë¡œë“œ**

**ì‹œì—° ë©˜íŠ¸**  
- â€œì˜¤ëŠ˜ ì‘ì—…ì˜ í•µì‹¬ì€ ìœ„ ì„¸ ê°€ì§€ì…ë‹ˆë‹¤. ë‹¤ ê°™ì´ í™•ì¸í•˜ê³  ì‹œì‘í•©ì‹œë‹¤.â€  
- â€œì ê¹ì´ë¼ë„ ì´ìƒí•˜ë©´ ë°”ë¡œ ì¤‘ì§€í•˜ê³ , ê´€ë¦¬ìì—ê²Œ ì•Œë¦½ë‹ˆë‹¤.â€  
- â€œì´ ì‚¬ë¡€ì—ì„œ ë°°ìš´ ì˜ˆë°© í¬ì¸íŠ¸ë¥¼ ì˜¤ëŠ˜ ì‘ì—…ì— ë°”ë¡œ ì ìš©í•©ì‹œë‹¤.â€  
- â€œê°ì ë§¡ì€ ê³µì •ì—ì„œ ë™ì¼ ìœ„í—˜ì´ ì—†ëŠ”ì§€ ë‹¤ì‹œ ì ê²€í•´ ì£¼ì„¸ìš”.â€
""")

st.title("ğŸ¦º OPS2TBM â€” OPS/í¬ìŠ¤í„°ë¥¼ TBM ëŒ€ë³¸ìœ¼ë¡œ ìë™ ë³€í™˜")

st.markdown("""
**ì•ˆë‚´**  
- í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ PDF ë˜ëŠ” ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.  
- ì´ë¯¸ì§€/ìŠ¤ìº”í˜• PDFëŠ” í˜„ì¬ OCR ë¯¸ì§€ì›ì…ë‹ˆë‹¤(í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ê²½ê³ ê°€ ëœ¹ë‹ˆë‹¤).
""")

col1, col2 = st.columns([1, 1], gap="large")

with col1:
    uploaded = st.file_uploader("OPS íŒŒì¼ ì—…ë¡œë“œ (í…ìŠ¤íŠ¸ PDF ê¶Œì¥)", type=["pdf"])
    manual_text = st.text_area("ë˜ëŠ” OPS í…ìŠ¤íŠ¸ ì§ì ‘ ë¶™ì—¬ë„£ê¸°", height=220, placeholder="ì˜ˆ: ì§€ë¶• ì‘ì—… ì¤‘ ì¶”ë½ì‚¬ê³  ì˜ˆë°©ì„ ìœ„í•´...")
    c1, c2 = st.columns(2)
    with c1:
        if st.button("ì‚¬ê³  ìƒ˜í”Œ ë„£ê¸°", use_container_width=True):
            manual_text = ("2020ë…„ 2ì›”, ì§€ë¶• ì¬ë¼ì´íŠ¸ ìœ„ ì‘ì—… ì¤‘ ì¶”ë½ ì¬í•´ ë°œìƒ. "
                           "ì‘ì—…ê³„íš ë¯¸í¡, ì¶”ë½ë°©ì§€ì„¤ë¹„ ë¯¸ì„¤ì¹˜, ê°ì‹œì ë¶€ì¬ê°€ ì£¼ìš” ì›ì¸. "
                           "ì˜ˆë°©: ì•ˆì „ë°œíŒ/ë‚œê°„/ë¼ì´í”„ë¼ì¸ ì„¤ì¹˜, ì·¨ì•½ë¶€ í‘œì‹œ, ê°ì‹œì ë°°ì¹˜.")
    with c2:
        if st.button("ê°€ì´ë“œ ìƒ˜í”Œ ë„£ê¸°", use_container_width=True):
            manual_text = ("ê°ì •ë…¸ë™ ê·¼ë¡œì ê±´ê°•ë³´í˜¸ ì•ˆë‚´. ê³ ê°ì˜ í­ì–¸Â·í­í–‰ ë“±ìœ¼ë¡œ ì¸í•œ ê±´ê°•ì¥í•´ ì˜ˆë°©ê³¼ ëŒ€ì‘ì ˆì°¨ ì œì‹œ. "
                           "ì‚¬ì—…ì£¼ëŠ” ì§€ì¹¨ ë§ˆë ¨Â·ì˜ˆë°©êµìœ¡Â·ìƒë‹´ ì§€ì›, ê·¼ë¡œìëŠ” ì¡°ì¹˜ ìš”êµ¬ ê°€ëŠ¥, ê³ ê°ì€ ì¡´ì¤‘ ì˜ë¬´. "
                           "í­ì–¸ ë°œìƒ ì‹œ: ì¤‘ì§€ ìš”ì²­ â†’ ë³´ê³  â†’ ê¸°ë¡ â†’ íœ´ì‹/ìƒë‹´Â·ì¹˜ë£Œ â†’ ì¬ë°œë°©ì§€ ëŒ€ì±….")

    extracted = ""
    if uploaded:
        with st.spinner("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
            data = uploaded.read()
            extracted = read_pdf_text(data)

    base_text = manual_text.strip() if manual_text.strip() else extracted.strip()
    st.markdown("**ì¶”ì¶œ/ì…ë ¥ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°**")
    edited_text = st.text_area("í…ìŠ¤íŠ¸", value=base_text, height=240)

with col2:
    # ëª¨ë“œ/í…œí”Œë¦¿ ì„ íƒ
    use_ai = st.toggle("ğŸ”¹ AI ìš”ì•½(TextRank) ì‚¬ìš©", value=True)
    tmpl_choice = st.selectbox("ğŸ§© í…œí”Œë¦¿", ["ìë™ ì„ íƒ", "ì‚¬ê³ ì‚¬ë¡€í˜•", "ê°€ì´ë“œí˜•"])

    if st.button("ğŸ› ï¸ TBM ëŒ€ë³¸ ìƒì„±", type="primary", use_container_width=True):
        if not edited_text.strip():
            st.warning("í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. PDF ì—…ë¡œë“œ(í…ìŠ¤íŠ¸ PDF) ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ í›„ ì‹œë„í•˜ì„¸ìš”.")
        else:
            # í…œí”Œë¦¿ ê²°ì •
            if tmpl_choice == "ìë™ ì„ íƒ":
                detected = detect_template(edited_text)
            else:
                detected = tmpl_choice

            with st.spinner("ëŒ€ë³¸ ìƒì„± ì¤‘..."):
                if detected == "ì‚¬ê³ ì‚¬ë¡€í˜•":
                    script, parts = make_tbm_accident(edited_text, use_ai=use_ai)
                    subtitle = "ì‚¬ê³ ì‚¬ë¡€í˜• í…œí”Œë¦¿ ì ìš©"
                else:
                    script, parts = make_tbm_guide(edited_text, use_ai=use_ai)
                    subtitle = "ê°€ì´ë“œí˜• í…œí”Œë¦¿ ì ìš©"

            st.success(f"ëŒ€ë³¸ ìƒì„± ì™„ë£Œ! ({subtitle}{' Â· AI ìš”ì•½' if use_ai else ''})")
            st.text_area("TBM ëŒ€ë³¸ ë¯¸ë¦¬ë³´ê¸°", value=script, height=420)

            c3, c4 = st.columns(2)
            with c3:
                st.download_button("â¬‡ï¸ TXT ë‹¤ìš´ë¡œë“œ", data=script.encode("utf-8"),
                                   file_name="tbm_script.txt", use_container_width=True)
            with c4:
                st.download_button("â¬‡ï¸ DOCX ë‹¤ìš´ë¡œë“œ", data=to_docx_bytes(script),
                                   file_name="tbm_script.docx", use_container_width=True)

st.caption("í˜„ì¬: ê·œì¹™ + ìˆœìˆ˜ NumPy TextRank(ê²½ëŸ‰ AI). í…œí”Œë¦¿ ìë™/ìˆ˜ë™. OCR ë¯¸ì§€ì›(í…ìŠ¤íŠ¸ PDF ê¶Œì¥).")
