# =========================
# OPS2TBM â€” ì•ˆì •íŒ + ê²½ëŸ‰ AI(TextRank) + ZIP ì¼ê´„ ì§€ì›
# - í…ìŠ¤íŠ¸ PDF / í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸° / ZIP(ì—¬ëŸ¬ PDF) ì§€ì›
# - í…œí”Œë¦¿: ìë™/ì‚¬ê³ ì‚¬ë¡€í˜•/ê°€ì´ë“œí˜• (ìˆ˜ë™ ì„ íƒ ê°€ëŠ¥)
# - AI ìš”ì•½: ìˆœìˆ˜ NumPy TextRank (ì„¤ì¹˜ ì´ìŠˆ ç„¡)
# - AIë¡œ ë½‘íŒ ë¬¸ì¥ â­[AI] ê°•ì¡° í‘œì‹œ
# - ì‚¬ì´ë“œë°”: ì†Œê°œ/ì‚¬ìš©ë²•/ì‹œì—° ë©˜íŠ¸
# =========================

import io
import zipfile
from typing import List, Tuple, Dict

import streamlit as st
from docx import Document
from docx.shared import Pt
from pdfminer.high_level import extract_text as pdf_extract_text
import pypdfium2 as pdfium
import numpy as np
import regex as rxx

# ----------------------------
# ê³µí†µ ìœ í‹¸
# ----------------------------
def normalize_text(text: str) -> str:
    text = text.replace("\x0c", "\n")
    text = rxx.sub(r"[ \t]+\n", "\n", text)
    text = rxx.sub(r"\n{3,}", "\n\n", text)
    return text.strip()

def read_pdf_text(file_bytes: bytes) -> str:
    # 1) pdfminerë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
    try:
        with io.BytesIO(file_bytes) as bio:
            text = pdf_extract_text(bio) or ""
    except Exception:
        text = ""
    text = normalize_text(text)

    # 2) í…ìŠ¤íŠ¸ ê±°ì˜ ì—†ìœ¼ë©´(ì´ë¯¸ì§€ PDF ì¶”ì •) í˜ì´ì§€ ìˆ˜ ì²´í¬ í›„ ì•ˆë‚´
    if len(text.strip()) < 10:
        try:
            with io.BytesIO(file_bytes) as bio:
                pdf = pdfium.PdfDocument(bio)
                pages = len(pdf)
            if pages > 0 and not text.strip():
                st.warning("ì´ PDFëŠ” ì´ë¯¸ì§€/ìŠ¤ìº” ê¸°ë°˜ìœ¼ë¡œ ë³´ì—¬ìš”. í˜„ì¬ ë²„ì „ì€ OCR ì—†ì´ 'í…ìŠ¤íŠ¸'ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        except Exception:
            pass
    return text

def split_sentences_ko(text: str) -> List[str]:
    raw = rxx.split(r"(?<=[\.!\?]|ë‹¤\.)\s+|\n+", text)
    return [s.strip() for s in raw if s and len(s.strip()) > 1]

def simple_tokens(s: str) -> List[str]:
    s = s.lower()
    return rxx.findall(r"[ê°€-í£a-z0-9]{2,}", s)

# ----------------------------
# ìˆœìˆ˜ NumPy TextRank
# ----------------------------
def sentence_tfidf_vectors(sents: List[str]) -> Tuple[np.ndarray, List[str]]:
    toks_list = [simple_tokens(s) for s in sents]
    vocab: Dict[str, int] = {}
    for toks in toks_list:
        for t in toks:
            if t not in vocab:
                vocab[t] = len(vocab)
    if not vocab:
        return np.zeros((len(sents), 0), dtype=np.float32), []
    mat = np.zeros((len(sents), len(vocab)), dtype=np.float32)
    df = np.zeros((len(vocab),), dtype=np.float32)
    for i, toks in enumerate(toks_list):
        for t in toks:
            j = vocab[t]
            mat[i, j] += 1.0
        for t in set(toks):
            df[vocab[t]] += 1.0
    N = float(len(sents))
    idf = np.log((N + 1.0) / (df + 1.0)) + 1.0
    mat *= idf
    norms = np.linalg.norm(mat, axis=1, keepdims=True) + 1e-8
    mat = mat / norms
    return mat, list(vocab.keys())

def cosine_sim_matrix(X: np.ndarray) -> np.ndarray:
    if X.size == 0:
        return np.zeros((X.shape[0], X.shape[0]), dtype=np.float32)
    sim = np.clip(X @ X.T, 0.0, 1.0)
    np.fill_diagonal(sim, 0.0)
    return sim

def textrank_scores(sents: List[str], d: float = 0.85, max_iter: int = 50, tol: float = 1e-4) -> List[float]:
    if len(sents) == 0:
        return []
    if len(sents) == 1:
        return [1.0]
    X, _ = sentence_tfidf_vectors(sents)
    W = cosine_sim_matrix(X)
    row_sums = W.sum(axis=1, keepdims=True)
    P = np.divide(W, row_sums, out=np.zeros_like(W), where=row_sums > 0)

    n = W.shape[0]
    r = np.ones((n, 1), dtype=np.float32) / n
    teleport = np.ones((n, 1), dtype=np.float32) / n

    for _ in range(max_iter):
        r_new = d * (P.T @ r) + (1 - d) * teleport
        if np.linalg.norm(r_new - r, ord=1) < tol:
            r = r_new
            break
        r = r_new
    return [float(v) for v in r.flatten()]

# ----------------------------
# ì„ íƒ ë¡œì§ (ê·œì¹™/AI) â€” AI ë¬¸ì¥ ê°•ì¡° ì§€ì›
# ----------------------------
def pick_rule(sents: List[str], keywords: List[str], limit: int) -> Tuple[List[str], List[bool]]:
    hits = [s for s in sents if any(k in s for k in keywords)]
    out = hits[:limit]
    flags = [False] * len(out)  # ê·œì¹™ ëª¨ë“œ â†’ AI ì•„ë‹˜
    if len(out) < limit:
        remain = [s for s in sents if s not in out]
        remain = sorted(remain, key=lambda x: (-len(x), sents.index(x)))
        add = remain[: max(0, limit - len(out))]
        out.extend(add)
        flags.extend([False] * len(add))
    return out, flags

def pick_tr(sents: List[str], keywords: List[str], limit: int, scores: List[float]) -> Tuple[List[str], List[bool]]:
    if not sents:
        return [], []
    w = np.array(scores, dtype=np.float32)
    if keywords:
        for i, s in enumerate(sents):
            if any(k in s for k in keywords):
                w[i] += 0.2
    idx = np.argsort(-w)[:limit]
    out = [sents[i] for i in idx]
    flags = [True] * len(out)  # AIë¡œ ì„ íƒë¨
    return out, flags

# ----------------------------
# í…œí”Œë¦¿/í‚¤ì›Œë“œ
# ----------------------------
# ê°€ì´ë“œí˜•
KW_GUIDE_CORE = ["ê°€ì´ë“œ","ì•ˆë‚´","ë³´í˜¸","ê±´ê°•","ëŒ€ì‘","ì ˆì°¨","ì§€ì¹¨","ë§¤ë‰´ì–¼","ì˜ˆë°©","ìƒë‹´","ì§€ì›","ì¡´ì¤‘"]
KW_GUIDE_STEP = ["ì ˆì°¨","ìˆœì„œ","ë°©ë²•","ì ê²€","í™•ì¸","ë³´ê³ ","ì¡°ì¹˜","ê¸°ë¡","íœ´ì‹"]
KW_GUIDE_QA   = ["ì§ˆë¬¸","ì™œ","ì–´ë–»ê²Œ","ë¬´ì—‡","ì£¼ì˜","í™•ì¸í• ", "í† ì˜"]

# ì‚¬ê³ ì‚¬ë¡€í˜•
KW_ACC_CORE = ["ì‚¬ê³ ","ì¬í•´","ìœ„í—˜","ì›ì¸","ì˜ˆë°©","ëŒ€ì±…","ë…¸í›„","ì¶”ë½","í˜‘ì°©","ê°ì „","í™”ì¬","ì§ˆì‹","ì¤‘ë…"]
KW_ACC_STEP = ["ë°œìƒ","ê²½ìœ„","ì¡°ì¹˜","ê°œì„ ","êµìœ¡","ì„¤ì¹˜","ë°°ì¹˜","ì ê²€","ê´€ë¦¬"]
KW_ACC_QA   = ["ì›ì¸ì€","ë‹¤ìŒì—ëŠ”","ì˜ˆë°©í•˜ë ¤ë©´","í™•ì¸í•  ì ","ì²´í¬","í† ì˜"]

def detect_template(text: str) -> str:
    g_hits = sum(text.count(k) for k in (KW_GUIDE_CORE + KW_GUIDE_STEP))
    a_hits = sum(text.count(k) for k in (KW_ACC_CORE + KW_ACC_STEP))
    return "ê°€ì´ë“œí˜•" if g_hits >= a_hits else "ì‚¬ê³ ì‚¬ë¡€í˜•"

# ----------------------------
# TBM ìƒì„± (ê° ì„¹ì…˜ì— AI ê°•ì¡° í‘œì‹œ)
# ----------------------------
def render_with_marks(lines: List[str], ai_flags: List[bool]) -> List[str]:
    out = []
    for s, ai in zip(lines, ai_flags):
        if ai:
            out.append(f"- â­[AI] {s}")
        else:
            out.append(f"- {s}")
    return out

def make_tbm_guide(text: str, use_ai: bool) -> Tuple[str, Dict[str, List[str]]]:
    sents = split_sentences_ko(text)
    if use_ai:
        scores = textrank_scores(sents)
        core, core_f = pick_tr(sents, KW_GUIDE_CORE, 3, scores)
    else:
        core, core_f = pick_rule(sents, KW_GUIDE_CORE, 3)
    steps, steps_f = pick_rule(sents, KW_GUIDE_STEP, 5)  # ì ˆì°¨ëŠ” ê·œì¹™ì´ ë” ì•ˆì •ì 
    qa, qa_f       = pick_rule(sents, KW_GUIDE_QA,   3)

    parts = {"í•µì‹¬": core, "ì ˆì°¨": steps, "ì§ˆë¬¸": qa}
    lines = []
    lines.append("ğŸ¦º TBM ëŒ€ë³¸ â€“ ê°€ì´ë“œí˜•")
    lines.append("")
    lines.append("â— ì˜¤ëŠ˜ì˜ í•µì‹¬ í¬ì¸íŠ¸")
    lines += render_with_marks(core, core_f)
    lines.append("")
    lines.append("â— ì‘ì—… ì „ ì ˆì°¨/ì ê²€")
    lines += render_with_marks(steps, steps_f)
    lines.append("")
    lines.append("â— í˜„ì¥ í† ì˜ ì§ˆë¬¸")
    lines += render_with_marks(qa, qa_f)
    lines.append("")
    lines.append("â— ë§ˆë¬´ë¦¬ ë©˜íŠ¸")
    lines.append("- â€œì˜¤ëŠ˜ ì‘ì—…ì˜ í•µì‹¬ì€ ìœ„ ì„¸ ê°€ì§€ì…ë‹ˆë‹¤. ë‹¤ ê°™ì´ í™•ì¸í•˜ê³  ì‹œì‘í•©ì‹œë‹¤.â€")
    lines.append("- â€œì ê¹ì´ë¼ë„ ì´ìƒí•˜ë©´ ë°”ë¡œ ì¤‘ì§€í•˜ê³ , ê´€ë¦¬ìì—ê²Œ ì•Œë¦½ë‹ˆë‹¤.â€")
    script = "\n".join(lines)
    return script, parts

def make_tbm_accident(text: str, use_ai: bool) -> Tuple[str, Dict[str, List[str]]]:
    sents = split_sentences_ko(text)
    if use_ai:
        scores = textrank_scores(sents)
        core, core_f = pick_tr(sents, KW_ACC_CORE, 3, scores)
    else:
        core, core_f = pick_rule(sents, KW_ACC_CORE, 3)
    steps, steps_f = pick_rule(sents, KW_ACC_STEP, 5)
    qa, qa_f       = pick_rule(sents, KW_ACC_QA,   3)

    parts = {"í•µì‹¬": core, "ì‚¬ê³ /ì¡°ì¹˜": steps, "ì§ˆë¬¸": qa}
    lines = []
    lines.append("ğŸ¦º TBM ëŒ€ë³¸ â€“ ì‚¬ê³ ì‚¬ë¡€í˜•")
    lines.append("")
    lines.append("â— ì‚¬ê³ /ìœ„í—˜ ìš”ì¸ ìš”ì•½")
    lines += render_with_marks(core, core_f)
    lines.append("")
    lines.append("â— ë°œìƒ ê²½ìœ„/ì¡°ì¹˜/ê°œì„ ")
    lines += render_with_marks(steps, steps_f)
    lines.append("")
    lines.append("â— ì¬ë°œ ë°©ì§€ í† ì˜ ì§ˆë¬¸")
    lines += render_with_marks(qa, qa_f)
    lines.append("")
    lines.append("â— ë§ˆë¬´ë¦¬ ë©˜íŠ¸")
    lines.append("- â€œì´ ì‚¬ë¡€ì—ì„œ ë°°ìš´ ì˜ˆë°© í¬ì¸íŠ¸ë¥¼ ì˜¤ëŠ˜ ì‘ì—…ì— ë°”ë¡œ ì ìš©í•©ì‹œë‹¤.â€")
    lines.append("- â€œê°ì ë§¡ì€ ê³µì •ì—ì„œ ë™ì¼ ìœ„í—˜ì´ ì—†ëŠ”ì§€ ë‹¤ì‹œ ì ê²€í•´ ì£¼ì„¸ìš”.â€")
    script = "\n".join(lines)
    return script, parts

# ----------------------------
# ë‚´ë³´ë‚´ê¸°
# ----------------------------
def to_docx_bytes(script: str) -> bytes:
    doc = Document()
    style = doc.styles["Normal"]
    style.font.name = "Malgun Gothic"
    style.font.size = Pt(11)
    for line in script.split("\n"):
        p = doc.add_paragraph(line)
        for run in p.runs:
            run.font.name = "Malgun Gothic"
            run.font.size = Pt(11)
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio.read()

# ----------------------------
# UI (ì¢Œ/ìš° 2ì—´ + ì‚¬ì´ë“œë°”)
# ----------------------------
st.set_page_config(page_title="OPS2TBM", page_icon="ğŸ¦º", layout="wide")

with st.sidebar:
    st.header("â„¹ï¸ ì†Œê°œ / ì‚¬ìš©ë²•")
    st.markdown("""
**ì´ ì•±ì€ ë¬´ì—‡ì„ í•˜ë‚˜ìš”?**  
OPS ë¬¸ì„œ(í…ìŠ¤íŠ¸ PDF/ë³¸ë¬¸ í…ìŠ¤íŠ¸/ZIP)ë¥¼ ë„£ìœ¼ë©´,  
- **ì‚¬ê³ ì‚¬ë¡€í˜•** ë˜ëŠ” **ê°€ì´ë“œí˜•** í…œí”Œë¦¿ìœ¼ë¡œ  
- í˜„ì¥ì—ì„œ ë°”ë¡œ ì½ì„ ìˆ˜ ìˆëŠ” **TBM ëŒ€ë³¸**ì„ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

**AI ê¸°ëŠ¥**  
- ê²½ëŸ‰ TextRank(ìˆœìˆ˜ NumPy)ë¡œ **í•µì‹¬ ë¬¸ì¥**ì„ ë„ì¶œí•˜ê³   
- ëŒ€ë³¸ì—ì„œ í•´ë‹¹ ë¬¸ì¥ì„ **â­[AI]** ë¡œ ê°•ì¡°í•©ë‹ˆë‹¤.

**ì‚¬ìš©ë²•**  
1) ì¢Œì¸¡ì— **íŒŒì¼ ì—…ë¡œë“œ**(PDF ë˜ëŠ” ZIP) ë˜ëŠ” **í…ìŠ¤íŠ¸ ë¶™ì—¬ë„£ê¸°**  
2) ìš°ì¸¡ì—ì„œ **AI ìš”ì•½ í† ê¸€**ê³¼ **í…œí”Œë¦¿(ìë™/ìˆ˜ë™)** ì„ íƒ  
3) **ëŒ€ë³¸ ìƒì„±** â†’ ë¯¸ë¦¬ë³´ê¸° â†’ **TXT/DOCX ë‹¤ìš´ë¡œë“œ**
""")

st.title("ğŸ¦º OPS2TBM â€” OPS/í¬ìŠ¤í„°ë¥¼ TBM ëŒ€ë³¸ìœ¼ë¡œ ìë™ ë³€í™˜")

st.markdown("""
**ì•ˆë‚´**  
- í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ PDF ë˜ëŠ” ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.  
- ZIP ì—…ë¡œë“œ ì‹œ ë‚´ë¶€ì˜ PDFë“¤ì„ ìë™ ì¸ì‹í•˜ì—¬ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
- ì´ë¯¸ì§€/ìŠ¤ìº”í˜• PDFëŠ” í˜„ì¬ OCR ë¯¸ì§€ì›ì…ë‹ˆë‹¤.
""")

col1, col2 = st.columns([1, 1], gap="large")

# ì¢Œì¸¡: ì…ë ¥
with col1:
    uploaded = st.file_uploader("OPS ì—…ë¡œë“œ (PDF ë˜ëŠ” ZIP) â€¢ í…ìŠ¤íŠ¸ PDF ê¶Œì¥", type=["pdf", "zip"])
    manual_text = st.text_area("ë˜ëŠ” OPS í…ìŠ¤íŠ¸ ì§ì ‘ ë¶™ì—¬ë„£ê¸°", height=220,
                               placeholder="ì˜ˆ: ì§€ë¶• ì‘ì—… ì¤‘ ì¶”ë½ì‚¬ê³  ì˜ˆë°©ì„ ìœ„í•´...")

    # ZIP ì²˜ë¦¬: ë‚´ë¶€ PDF ë‚˜ì—´
    zip_pdfs: Dict[str, bytes] = {}
    selected_zip_pdf = None
    if uploaded and uploaded.name.lower().endswith(".zip"):
        try:
            with zipfile.ZipFile(uploaded, "r") as zf:
                for name in zf.namelist():
                    if name.lower().endswith(".pdf"):
                        zip_pdfs[name] = zf.read(name)
        except Exception:
            st.error("ZIPì„ í•´ì œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        if zip_pdfs:
            selected_zip_pdf = st.selectbox("ZIP ë‚´ PDF ì„ íƒ", list(zip_pdfs.keys()))
        else:
            st.warning("ZIP ì•ˆì—ì„œ PDFë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    extracted = ""
    if uploaded and uploaded.name.lower().endswith(".pdf"):
        with st.spinner("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
            data = uploaded.read()
            extracted = read_pdf_text(data)
    elif selected_zip_pdf:
        with st.spinner("ZIP ë‚´ë¶€ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì¤‘..."):
            extracted = read_pdf_text(zip_pdfs[selected_zip_pdf])

    base_text = manual_text.strip() if manual_text.strip() else extracted.strip()
    st.markdown("**ì¶”ì¶œ/ì…ë ¥ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°**")
    edited_text = st.text_area("í…ìŠ¤íŠ¸", value=base_text, height=240)

# ìš°ì¸¡: ì˜µì…˜/ìƒì„±/ë‹¤ìš´ë¡œë“œ
with col2:
    use_ai = st.toggle("ğŸ”¹ AI ìš”ì•½(TextRank) ì‚¬ìš©", value=True)
    tmpl_choice = st.selectbox("ğŸ§© í…œí”Œë¦¿", ["ìë™ ì„ íƒ", "ì‚¬ê³ ì‚¬ë¡€í˜•", "ê°€ì´ë“œí˜•"])

    if st.button("ğŸ› ï¸ TBM ëŒ€ë³¸ ìƒì„±", type="primary", use_container_width=True):
        if not edited_text.strip():
            st.warning("í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. PDF/ZIP ì—…ë¡œë“œ ë˜ëŠ” í…ìŠ¤íŠ¸ ì…ë ¥ í›„ ì‹œë„í•˜ì„¸ìš”.")
        else:
            # í…œí”Œë¦¿ ê²°ì •
            if tmpl_choice == "ìë™ ì„ íƒ":
                detected = detect_template(edited_text)
            else:
                detected = tmpl_choice

            with st.spinner("ëŒ€ë³¸ ìƒì„± ì¤‘..."):
                if detected == "ì‚¬ê³ ì‚¬ë¡€í˜•":
                    script, parts = make_tbm_accident(edited_text, use_ai=use_ai)
                    subtitle = "ì‚¬ê³ ì‚¬ë¡€í˜• í…œí”Œë¦¿ ì ìš©"
                else:
                    script, parts = make_tbm_guide(edited_text, use_ai=use_ai)
                    subtitle = "ê°€ì´ë“œí˜• í…œí”Œë¦¿ ì ìš©"

            st.success(f"ëŒ€ë³¸ ìƒì„± ì™„ë£Œ! ({subtitle}{' Â· AI ìš”ì•½' if use_ai else ''})")
            st.text_area("TBM ëŒ€ë³¸ ë¯¸ë¦¬ë³´ê¸°", value=script, height=420)

            c3, c4 = st.columns(2)
            with c3:
                st.download_button("â¬‡ï¸ TXT ë‹¤ìš´ë¡œë“œ", data=script.encode("utf-8"),
                                   file_name="tbm_script.txt", use_container_width=True)
            with c4:
                st.download_button("â¬‡ï¸ DOCX ë‹¤ìš´ë¡œë“œ", data=to_docx_bytes(script),
                                   file_name="tbm_script.docx", use_container_width=True)

st.caption("í˜„ì¬: ê·œì¹™ + ìˆœìˆ˜ NumPy TextRank(ê²½ëŸ‰ AI). í…œí”Œë¦¿ ìë™/ìˆ˜ë™. ZIP ì¼ê´„ ì§€ì›. OCR ë¯¸ì§€ì›(í…ìŠ¤íŠ¸ PDF ê¶Œì¥).")
