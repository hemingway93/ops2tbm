# ==========================================================
# OPS2TBM â€” ì™„ì „ ë¬´ë£Œ AI ë²„ì „ (ê·œì¹™ ì¤€ìˆ˜)
# ì‘ì„± ëª©ì :
#   - ê¸°ì¡´ UI/ë ˆì´ì•„ì›ƒ ìœ ì§€
#   - AI ìš”ì•½(TextRank+MMR) + ë¬¸ì²´ ë³€í™˜ + 3ë¶„í˜• êµìœ¡ëŒ€ë³¸ ìë™ êµ¬ì„±
# ==========================================================

import io, zipfile
from typing import List, Tuple
import streamlit as st
from docx import Document
from docx.shared import Pt
from pdfminer.high_level import extract_text as pdf_extract_text
import pypdfium2 as pdfium
import numpy as np
import regex as rxx

# ==========================================================
# 1ï¸âƒ£ ê¸°ë³¸ ì„¸íŒ… ë° ê³µí†µ í•¨ìˆ˜
# ==========================================================

if "uploader_key" not in st.session_state:
    st.session_state.uploader_key = 0

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í…ìŠ¤íŠ¸ ì •ë¦¬ (ê³µë°±/ì¤„ë°”ê¿ˆ ì •ë¦¬)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def normalize_text(t: str) -> str:
    t = t.replace("\x0c", "\n")
    t = rxx.sub(r"[ \t]+\n", "\n", t)
    t = rxx.sub(r"\n{3,}", "\n\n", t)
    return t.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ (í…ìŠ¤íŠ¸í˜• PDFë§Œ ê°€ëŠ¥)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def read_pdf_text(b: bytes) -> str:
    try:
        with io.BytesIO(b) as bio:
            text = pdf_extract_text(bio) or ""
    except Exception:
        text = ""
    text = normalize_text(text)
    if len(text.strip()) < 10:
        try:
            pdf = pdfium.PdfDocument(io.BytesIO(b))
            if len(pdf) > 0:
                st.warning("âš ï¸ OCR ë¯¸ì§€ì› PDFì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        except Exception:
            pass
    return text

# ==========================================================
# 2ï¸âƒ£ AI ìš”ì•½(TextRank + MMR)
# ==========================================================
# OPS ë¬¸ì„œì—ì„œ ë¬¸ì¥ ê°„ ì˜ë¯¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•´ í•µì‹¬ ë¬¸ì¥ë§Œ ì¶”ì¶œí•˜ëŠ” ë¹„ì§€ë„ AI ë°©ì‹

def split_sentences_ko(text: str) -> List[str]:
    raw = rxx.split(r"(?<=[\.!\?]|ë‹¤\.)\s+|\n+", text)
    return [s.strip(" -â€¢â—â–ªâ–¶â–·\t") for s in raw if len(s.strip()) > 5]

def simple_tokens(s: str) -> List[str]:
    return rxx.findall(r"[ê°€-í£a-z0-9]{2,}", s.lower())

def sentence_tfidf_vectors(sents: List[str]):
    toks = [simple_tokens(s) for s in sents]
    vocab = {}
    for ts in toks:
        for t in ts:
            if t not in vocab:
                vocab[t] = len(vocab)
    if not vocab:
        return np.zeros((len(sents), 0)), []
    M = np.zeros((len(sents), len(vocab)))
    df = np.zeros(len(vocab))
    for i, ts in enumerate(toks):
        for t in ts:
            M[i, vocab[t]] += 1
        for t in set(ts):
            df[vocab[t]] += 1
    idf = np.log((len(sents) + 1) / (df + 1)) + 1
    M *= idf
    M /= np.linalg.norm(M, axis=1, keepdims=True) + 1e-8
    return M, list(vocab.keys())

def cosine_sim_matrix(X):
    if X.size == 0:
        return np.zeros((X.shape[0], X.shape[0]))
    sim = np.clip(X @ X.T, 0, 1)
    np.fill_diagonal(sim, 0)
    return sim

def textrank_scores(sents: List[str]) -> List[float]:
    n = len(sents)
    if n == 0:
        return []
    X, _ = sentence_tfidf_vectors(sents)
    W = cosine_sim_matrix(X)
    row = W.sum(1, keepdims=True)
    P = np.divide(W, row, out=np.zeros_like(W), where=row > 0)
    r = np.ones((n, 1)) / n
    for _ in range(50):
        r_new = 0.85 * P.T @ r + 0.15 / n
        if np.linalg.norm(r_new - r) < 1e-4:
            break
        r = r_new
    return [float(x) for x in r.flatten()]

def mmr_select(sents, scores, X, k=6):
    sim = cosine_sim_matrix(X)
    sel = []
    cand = set(range(len(sents)))
    while cand and len(sel) < k:
        best, bestv = None, -1e9
        for i in cand:
            rel = scores[i]
            div = max((sim[i, j] for j in sel), default=0)
            mmr = 0.7 * rel - 0.3 * div
            if mmr > bestv:
                bestv, best = mmr, i
        sel.append(best)
        cand.remove(best)
    return sel

def ai_extract_summary(text: str, limit: int = 8) -> List[str]:
    sents = split_sentences_ko(text)
    if not sents:
        return []
    X, _ = sentence_tfidf_vectors(sents)
    scores = textrank_scores(sents)
    idx = mmr_select(sents, scores, X, limit)
    return [sents[i] for i in idx]

# ==========================================================
# 3ï¸âƒ£ ê·œì¹™ ê¸°ë°˜ ë¬¸ì²´ ë³€í™˜ + 3ë¶„ êµìœ¡ëŒ€ë³¸ ìë™ êµ¬ì„±
# ==========================================================

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì£¼ìš” ë‹¨ì–´ë³„ ì£¼ì œ ê°ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def detect_topic(t: str) -> str:
    if "ì˜¨ì—´" in t or "í­ì—¼" in t:
        return "ì˜¨ì—´ì§ˆí™˜ ì˜ˆë°©"
    if "ì§ˆì‹" in t or "ë°€í" in t:
        return "ì§ˆì‹ì¬í•´ ì˜ˆë°©"
    if "ê°ì „" in t:
        return "ê°ì „ì‚¬ê³  ì˜ˆë°©"
    if "ì§€ë¶•" in t or "ì¬ë¼ì´íŠ¸" in t:
        return "ì§€ë¶• ì‘ì—… ì¶”ë½ì‚¬ê³  ì˜ˆë°©"
    if "ì»¨ë² ì´ì–´" in t or "ë¼ì„" in t:
        return "ì»¨ë² ì´ì–´ ë¼ì„ì‚¬ê³  ì˜ˆë°©"
    return "ì•ˆì „ë³´ê±´ êµìœ¡"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¬¸ì²´ ì™„í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def soften(s: str) -> str:
    s = s.replace("í•œë‹¤", "í•©ë‹ˆë‹¤").replace("í•˜ì—¬ì•¼", "í•´ì•¼ í•©ë‹ˆë‹¤")
    s = s.replace("ë°”ëë‹ˆë‹¤", "í•´ì£¼ì„¸ìš”").replace("í™•ì¸ ë°”ëŒ", "í™•ì¸í•´ì£¼ì„¸ìš”")
    return s.strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3ë¶„ êµìœ¡ëŒ€ë³¸ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_structured_script(text: str) -> str:
    topic = detect_topic(text)
    core = ai_extract_summary(text, 8)
    if not core:
        return "ë³¸ë¬¸ì´ ì¶©ë¶„í•˜ì§€ ì•Šì•„ ëŒ€ë³¸ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    intro, case, risk, act, ask = [], [], [], [], []
    for s in core:
        st = soften(s)
        if any(k in s for k in ["ì‚¬ê³ ", "ë°œìƒ", "ì‚¬ë¡€", "ì‚¬ë§"]):
            case.append(st)
        elif any(k in s for k in ["ìœ„í—˜", "ìš”ì¸", "ì›ì¸"]):
            risk.append(st)
        elif any(k in s for k in ["ì¡°ì¹˜", "ì˜ˆë°©", "ì°©ìš©", "ì„¤ì¹˜", "ì ê²€", "íœ´ì‹", "ê³µê¸‰"]):
            act.append(st)
        elif "?" in s or "í™•ì¸" in s:
            ask.append(st)
        else:
            intro.append(st)

    lines = []
    lines.append(f"ğŸ¦º TBM êµìœ¡ëŒ€ë³¸ â€“ {topic}\n")
    lines.append("â— ë„ì…")
    lines.append(f"ì˜¤ëŠ˜ì€ {topic}ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê² ìŠµë‹ˆë‹¤. í˜„ì¥ì—ì„œ ìì£¼ ë°œìƒí•˜ì§€ë§Œ, ì˜ˆë°©ë§Œìœ¼ë¡œ ì¶©ë¶„íˆ ë§‰ì„ ìˆ˜ ìˆëŠ” ë¶€ë¶„ì…ë‹ˆë‹¤.\n")

    if case:
        lines.append("â— ì‚¬ê³  ì‚¬ë¡€")
        for c in case:
            lines.append(f"- {c}")
        lines.append("")
    if risk:
        lines.append("â— ì£¼ìš” ìœ„í—˜ìš”ì¸")
        for r in risk:
            lines.append(f"- {r}")
        lines.append("")
    if act:
        lines.append("â— ì˜ˆë°©ì¡°ì¹˜ / ì‹¤ì²œ ìˆ˜ì¹™")
        for i, a in enumerate(act[:5], 1):
            lines.append(f"{i}ï¸âƒ£ {a}")
        lines.append("")
    if ask:
        lines.append("â— í˜„ì¥ ì ê²€ ì§ˆë¬¸")
        for q in ask:
            lines.append(f"- {q}")
        lines.append("")
    lines.append("â— ë§ˆë¬´ë¦¬ ë‹¹ë¶€")
    lines.append("ì•ˆì „ì€ í•œìˆœê°„ì˜ ê´€ì‹¬ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤. ì˜¤ëŠ˜ ì‘ì—… ì „ ì„œë¡œ í•œ ë²ˆ ë” í™•ì¸í•©ì‹œë‹¤.")
    lines.append("â— êµ¬í˜¸")
    lines.append("â€œí•œ ë²ˆ ë” í™•ì¸! í•œ ë²ˆ ë” ì ê²€!â€")

    return "\n".join(lines)

# ==========================================================
# 4ï¸âƒ£ DOCX ì €ì¥
# ==========================================================
def to_docx_bytes(script: str) -> bytes:
    doc = Document()
    style = doc.styles["Normal"]
    style.font.name = "Malgun Gothic"
    style.font.size = Pt(11)
    for line in script.split("\n"):
        doc.add_paragraph(line)
    bio = io.BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio.read()

# ==========================================================
# 5ï¸âƒ£ Streamlit UI (ë³€ê²½ ì—†ìŒ)
# ==========================================================
st.set_page_config(page_title="OPS2TBM", page_icon="ğŸ¦º", layout="wide")

with st.sidebar:
    st.header("â„¹ï¸ ì†Œê°œ / ì‚¬ìš©ë²•")
    st.markdown("""
**AI ê¸°ëŠ¥(ì™„ì „ ë¬´ë£Œ)**  
- TextRank + MMR ê¸°ë°˜ ìš”ì•½ (ë¹„ì§€ë„ AI)
- ê·œì¹™ ê¸°ë°˜ ë¬¸ì²´ ë³€í™˜ (ìƒì„±í˜• AI ëŒ€ì²´)
- OPS ë¬¸ì„œì—ì„œ ìë™ìœ¼ë¡œ 3ë¶„ êµìœ¡ëŒ€ë³¸ êµ¬ì„±
""")

st.title("ğŸ¦º OPS2TBM â€” OPS ë¬¸ì„œë¥¼ AIë¡œ êµìœ¡ëŒ€ë³¸ ìë™ ë³€í™˜ (ì™„ì „ ë¬´ë£Œ)")

def reset_all():
    st.session_state.pop("manual_text", None)
    st.session_state.pop("edited_text", None)
    st.session_state.uploader_key += 1
    st.rerun()

col1, col2 = st.columns([4, 1])
with col2:
    st.button("ğŸ§¹ ì´ˆê¸°í™”", on_click=reset_all, use_container_width=True)

uploaded = st.file_uploader("OPS ì—…ë¡œë“œ (PDF ë˜ëŠ” ZIP)", type=["pdf", "zip"])
manual = st.text_area("ë˜ëŠ” í…ìŠ¤íŠ¸ ì§ì ‘ ë¶™ì—¬ë„£ê¸°", height=200)
text = ""

if uploaded and uploaded.name.lower().endswith(".pdf"):
    text = read_pdf_text(uploaded.read())
elif manual.strip():
    text = manual

colL, colR = st.columns(2)
with colL:
    st.text_area("ğŸ“„ ì¶”ì¶œëœ í…ìŠ¤íŠ¸", text, height=300, key="edited_text")
with colR:
    mode = st.selectbox("ğŸ§  ìƒì„± ëª¨ë“œ", ["TBM ê¸°ë³¸(í˜„í–‰)", "ìì—°ìŠ¤ëŸ¬ìš´ êµìœ¡ëŒ€ë³¸(ë¬´ë£ŒÂ·3ë¶„í˜•)"])
    if st.button("ğŸ› ï¸ ëŒ€ë³¸ ìƒì„±", type="primary", use_container_width=True):
        if not text.strip():
            st.warning("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
        else:
            with st.spinner("AI ìš”ì•½ + ëŒ€ë³¸ ìƒì„± ì¤‘..."):
                if mode.startswith("ìì—°ìŠ¤ëŸ¬ìš´"):
                    script = make_structured_script(text)
                else:
                    sents = ai_extract_summary(text, 6)
                    script = "\n".join([f"- {soften(s)}" for s in sents])
            st.success("âœ… ëŒ€ë³¸ ìƒì„± ì™„ë£Œ!")
            st.text_area("ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°", script, height=420)
            c1, c2 = st.columns(2)
            with c1:
                st.download_button("â¬‡ï¸ TXT", data=script.encode("utf-8"), file_name="tbm_script.txt")
            with c2:
                st.download_button("â¬‡ï¸ DOCX", data=to_docx_bytes(script), file_name="tbm_script.docx")
